{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Percona Distribution for PostgreSQL 16 Documentation","text":"<p>Percona Distribution for PostgreSQL is a collection of tools to assist you in managing your PostgreSQL database system: it installs PostgreSQL and complements it by a selection of extensions that enable solving essential practical tasks efficiently.</p> <p>What\u2019s included in the Distribution</p> <p>Get started What\u2019s new</p> <p>See also</p> <p>Percona Blog:</p> <ul> <li>pgBackRest - A Great Backup Solution and a Wonderful Year of   Growth</li> <li>Securing PostgreSQL as an Enterprise-Grade   Environment</li> </ul> <p>Percona Distribution for PostgreSQL is also shipped with the libpq library. It contains \u201ca set of library functions that allow client programs to pass queries to the PostgreSQL backend server and to receive the results of these queries.\u201d</p>"},{"location":"index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt.html","title":"Install Percona Distribution for PostgreSQL on Debian and Ubuntu","text":"<p>This document describes how to install Percona Server for PostgreSQL from Percona repositories on DEB-based distributions such as Debian and Ubuntu. Read more about Percona repositories .</p>"},{"location":"apt.html#preconditions","title":"Preconditions","text":"<ol> <li>Debian and other systems that use the <code>apt</code> package manager include the upstream PostgreSQL server package <code>postgresql-16</code> by default. The components of Percona Distribution for PostgreSQL 16 can only be installed together with the PostgreSQL server shipped by Percona (<code>percona-postgresql-16</code>). If you wish to use Percona Distribution for PostgreSQL, uninstall the <code>postgresql-16</code>  package provided by your distribution and then install the chosen components from Percona Distribution for PostgreSQL.</li> <li>Install <code>curl</code> for Telemetry. We use it to better understand the use of our products and improve them.</li> </ol>"},{"location":"apt.html#procedure","title":"Procedure","text":"<p>Run all the commands in the following sections as root or using the <code>sudo</code> command:</p>"},{"location":"apt.html#configure-percona-repository","title":"Configure Percona repository","text":"<ol> <li> <p>Install the <code>percona-release</code> repository management tool to subscribe to Percona repositories:</p> <ul> <li> <p>Fetch <code>percona-release</code> packages from Percona web:</p> <pre><code>$ wget https://repo.percona.com/apt/percona-release_latest.$(lsb_release -sc)_all.deb\n</code></pre> </li> <li> <p>Install the downloaded package with <code>dpkg</code>:</p> <pre><code>$ sudo dpkg -i percona-release_latest.$(lsb_release -sc)_all.deb\n</code></pre> </li> <li> <p>Refresh the local cache:</p> <pre><code>$ sudo apt update\n</code></pre> </li> </ul> </li> <li> <p>Enable the repository</p> </li> </ol> <p>Percona provides two repositories for Percona Distribution for PostgreSQL. We recommend enabling the Major release repository to timely receive the latest updates. </p> <pre><code>$ sudo percona-release setup ppg-16\n</code></pre>"},{"location":"apt.html#install-packages","title":"Install packages","text":"Install using meta-packageInstall packages individually <p>The meta package enables you to install several components of the distribution in one go.</p> <pre><code>$ sudo apt install percona-ppg-server-16\n</code></pre> <ol> <li> <p>Install the PostgreSQL server package:</p> <pre><code>$ sudo apt install percona-postgresql-16\n</code></pre> </li> <li> <p>Install the components:</p> <p>Install <code>pg_repack</code>:</p> <pre><code>$ sudo apt install percona-postgresql-16-repack\n</code></pre> <p>Install <code>pgAudit</code>:</p> <pre><code>$ sudo apt install percona-postgresql-16-pgaudit\n</code></pre> <p>Install <code>pgBackRest</code>:</p> <pre><code>$ sudo apt install percona-pgbackrest\n</code></pre> <p>Install <code>Patroni</code>:</p> <pre><code>$ sudo apt install percona-patroni\n</code></pre> <p>Install <code>pg_stat_monitor</code></p> <p>Install <code>pgBouncer</code>:</p> <pre><code>$ sudo apt install percona-pgbouncer\n</code></pre> <p>Install <code>pgAudit-set_user</code>:</p> <pre><code>$ sudo apt install percona-pgaudit16-set-user\n</code></pre> <p>Install <code>pgBadger</code>:</p> <pre><code>$ sudo apt install percona-pgbadger\n</code></pre> <p>Install <code>wal2json</code>:</p> <pre><code>$ sudo apt install percona-postgresql-16-wal2json\n</code></pre> <p>Install PostgreSQL contrib extensions:</p> <pre><code>$ sudo apt install percona-postgresql-contrib\n</code></pre> <p>Install HAProxy</p> <pre><code>$ sudo apt install percona-haproxy\n</code></pre> <p>Install pgpool2</p> <pre><code>$ sudo apt install percona-pgpool2\n</code></pre> <p>Install <code>pg_gather</code></p> <pre><code>$ sudo apt install percona-pg-gather\n</code></pre> <p>Some extensions require additional setup in order to use them with Percona Distribution for PostgreSQL. For more information, refer to Enabling extensions.</p> </li> </ol>"},{"location":"apt.html#start-the-service","title":"Start the service","text":"<p>The installation process automatically initializes and starts the default database. You can check the database status using the following command:</p> <pre><code>$ sudo systemctl status postgresql.service\n</code></pre>"},{"location":"apt.html#connect-to-the-postgresql-server","title":"Connect to the PostgreSQL server","text":"<p>By default, the <code>postgres</code> user and the <code>postgres</code> database are created in PostgreSQL upon its installation and initialization. This allows you to connect to the database as the <code>postgres</code> user.</p> <pre><code>$ sudo su postgres\n</code></pre> <p>Open the PostgreSQL interactive terminal:</p> <pre><code>$ psql\n</code></pre> <p>Hint</p> <p>You can connect to <code>psql</code> as the <code>postgres</code> user in one go:</p> <pre><code>$ sudo su - postgres -c psql\n</code></pre> <p>To exit the <code>psql</code> terminal, use the following command:</p> <pre><code>$ \\q\n</code></pre>"},{"location":"apt.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"contrib.html","title":"PostgreSQL contrib modules and utilities","text":"<p>Find the list of controb modules and extensions included in Percona Distribution for PostgtreSQL.</p> Name Database superuser Description adminpack Required Support toolpack for pgAdmin to provide additional functionality like remote management of server log files. amcheck Required Provides functions to verify the logical consistency of the structure of indexes, such as B-trees. It\u2019s useful for detecting system catalog corruption and index corruption. auth_delay Required Causes the server to pause briefly before reporting authentication failure, to make brute-force attacks on database passwords more difficult. auto_explain Required Automatically logs execution plans of slow SQL statements. It helps in performance analysis by tracking down un-optimized queries in large applications that exceed a specified time threshold. basebackup_to_shell Adds a custom basebackup target called <code>shell</code>. This enables an administartor to make a base backup of a running PostgreSQL server to a shell archive. basic-archive Required An archive module that copies completed WAL segment files to the specified directory. Can be used as a starting point for developing own archive module. bloom Required Provides an index access method based on Bloom filters.  A Bloom filter is a space-efficient data structure that is used to test whether an element is a member of a set. btree_gin Required Provides GIN index operator classes with B-tree-like behavior. This allows you to use GIN indexes, which are typically used for full-text search, in situations where you might otherwise use a B-tree index, such as with integer or text data. btree_gist Required Provides GiST (Generalized Search Tree) index operator classes that implement B-tree-like behavior. This allows you to use GiST indexes, which are typically used for multidimensional and non-scalar data, in situations where you might otherwise use a B-tree index, such as with integer or text data. citext Provides a case-insensitive character string type, citext. Essentially, it internally calls <code>lower</code> when comparing values. Otherwise, it behaves almost exactly like <code>text</code>. cube Implements a data type cube for representing multidimensional cubes dblink Required Provides functions to connect to other PostgreSQL databases from within a database session. This allows for queries to be run across multiple databases as if they were on the same server. dict_int An example of an add-on dictionary template for full-text search. It\u2019s used to demonstrate how to create custom dictionaries in PostgreSQL. dict_xsyn Required Example synonym full-text search dictionary. This dictionary type replaces words with groups of their synonyms, and so makes it possible to search for a word using any of its synonyms. earthdistance Required This module  provides two different approaches to calculating great circle distances on the surface of the Earth. The fisrt one depends on the <code>cube</code> module. The second one is based on the built-in <code>point</code> data type, using longitude and latitude for the coordinates. hstore Implements the <code>hstore</code> data type for storing sets of key/value pairs within a single PostgreSQL value. intagg Integer aggregator and enumerator. intarray Provides a number of useful functions and operators for manipulating null-free arrays of integers. isn Provides data types for the following international product numbering standards: EAN13, UPC, ISBN (books), ISMN (music), and ISSN (serials). lo Provides support for managing Large Objects (also called LOs or BLOBs). This includes a data type lo and a trigger lo_manage. ltree Implements a data type <code>ltree</code> for representing labels of data stored in a hierarchical tree-like structure. Extensive facilities for searching through label trees are provided. oldsnapshot Required Allows inspection of the server state that is used to implement old_snapshot_threshold. pageinspect Required Provides functions that allow you to inspect the contents of database pages at a low level, which is useful for debugging purposes. passwordcheck Checks users\u2019 passwords whenever they are set with CREATE ROLE or ALTER ROLE. If a password is considered too weak, it will be rejected and the command will terminate with an error. pg_buffercache Required Provides the set of functions for examining what\u2019s happening in the shared buffer cache in real time. pgcrypto Required Provides cryptographic functions for PostgreSQL. pg_freespacemap Required Provides a means of examining the free space map (FSM), which PostgreSQL uses to track the locations of available space in tables and indexes. This can be useful for understanding space utilization and planning for maintenance operations. pg_prewarm Provides a convenient way to load relation data into either the operating system buffer cache or the PostgreSQL buffer cache. This can be useful for reducing the time needed for a newly started database to reach its full performance potential by preloading frequently accessed data. pgrowlocks Required Provides a function to show row locking information for a specified table. pg_stat_statements Required A module for tracking planning and execution statistics of all SQL statements executed by a server. Consider using an advanced version of <code>pg_stat_statements</code> - <code>pg_stat_monitor</code> pgstattuple Required Povides various functions to obtain tuple-level statistics. It offers detailed information about tables and indexes, such as the amount of free space and the number of live and dead tuples. pg_surgery Required Provides various functions to perform surgery on a damaged relation. These functions are unsafe by design and using them may corrupt (or further corrupt) your database. Use them with caution and only as a last resort pg_trgm Provides functions and operators for determining the similarity of alphanumeric text based on trigram matching. A trigram is a contiguous sequence of three characters. The extension can be used for text search and pattern matching operations. pg_visibility Required Provides a way to examine the visibility map (VM) and the page-level visibility information of a table. It also provides functions to check the integrity of a visibility map and to force it to be rebuilt. pg_walinspect Required Provides SQL functions that allow you to inspect the contents of write-ahead log of a running PostgreSQL database cluster at a low level, which is useful for debugging, analytical, reporting or educational purposes. postgres_fdw Required Provides a Foreign Data Wrapper (FDW) for accessing data in remote PostgreSQL servers. It allows a PostgreSQL database to interact with remote tables as if they were local. seg Implements a data type <code>seg</code> for representing line segments, or floating point intervals. <code>seg</code> can represent uncertainty in the interval endpoints, making it especially useful for representing laboratory measurements. segpgsql SELinux-, label-based mandatory access control (MAC) security module. It can only be used on Linux 2.6.28 or higher with SELinux enabled. spi Required Provides several workable examples of using the Server Programming Interface (SPI) and triggers. sslinfo Reqjuired Provides information about the SSL certificate that the current client provided when connecting to PostgreSQL. tablefunc Includes various functions that return tables (that is, multiple rows). These functions are useful both in their own right and as examples of how to write C functions that return multiple rows. tcn Provides a trigger function that notifies listeners of changes to any table on which it is attached. test_decoding Required An SQL-based test/example module for WAL logical decoding tsm_system_rows Provides the table sampling method SYSTEM_ROWS, which can be used in the TABLESAMPLE clause of a SELECT command. tsm_system_time Provides the table sampling method  SYSTEM_TIME, which can be used in the TABLESAMPLE clause of a SELECT command. unaccent A text search dictionary that removes accents (diacritic signs) from lexemes. It\u2019s a filtering dictionary, which means its output is always passed to the next dictionary (if any). This allows accent-insensitive processing for full text search. uuid-ossp Required Provides functions to generate universally unique identifiers (UUIDs) using one of several standard algorithms xml2 Required Provides XPath querying and XSLT functionality. It allows for complex querying and transformation of XML data stored in PostgreSQL."},{"location":"contrib.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"docker.html","title":"Run Percona Distribution for PostgreSQL in a Docker container","text":"<p>Docker images of Percona Distribution for PostgreSQL are hosted publicly on Docker Hub.</p> <p>For more information about using Docker, see the Docker Docs.</p> <p>Make sure that you are using the latest version of Docker. The ones provided via <code>apt</code> and <code>yum</code> may be outdated and cause errors.</p> <p>By default, Docker pulls the image from Docker Hub if it is not available locally.</p> Docker image contents <p>The Docker image of Percona Distribution for PostgreSQL includes the following components:    </p> Component name Description <code>percona-postgresql16</code> A metapackage that installs the latest version of PostgreSQL <code>percona-postgresql16-server</code> The PostgreSQL server package. <code>percona-postgresql-common</code> PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. <code>percona-postgresql-client-common</code> The manager for multiple PostgreSQL client versions. <code>percona-postgresql16-contrib</code> A collection of additional PostgreSQLcontrib extensions <code>percona-postgresql16-libs</code> Libraries for use with PostgreSQL. <code>percona-pg-stat-monitor16</code> A Query Performance Monitoring tool for PostgreSQL. <code>percona-pgaudit16</code> Provides detailed session or object audit logging via the standard PostgreSQL logging facility. <code>percona-pgaudit16_set_user</code> An additional layer of logging and control when unprivileged users must escalate themselves to superuser or object owner roles in order to perform needed maintenance tasks. <code>percona-pg_repack16</code> rebuilds PostgreSQL database objects. <code>percona-wal2json16</code> a PostgreSQL logical decoding JSON output plugin."},{"location":"docker.html#start-the-container","title":"Start the container","text":"<ol> <li> <p>Start a Percona Distribution for PostgreSQL container as follows:</p> <pre><code>$ docker run --name container-name -e POSTGRES_PASSWORD=secret -d percona/percona-distribution-postgresql:&lt;tag&gt;-multi\n</code></pre> <p>Where:    </p> <ul> <li><code>container-name</code> is the name you assign to your container</li> <li><code>POSTGRES_PASSWORD</code> is the superuser password </li> <li><code>tag-multi</code> is the tag specifying the version you need. For example, <code>16.2-multi</code>. The <code>multi</code> part of the tag serves to identify the architecture (x86_64 or ARM64) and pull the respective image. See the full list of tags.     </li> </ul> <p>Tip</p> <p>You can secure the password by exporting it to the environment file and using that to start the container.    </p> <ol> <li> <p>Export the password to the environment file:    </p> <pre><code>$ echo \"POSTGRES_PASSWORD=secret\" &gt; .my-pg.env\n</code></pre> </li> <li> <p>Start the container:       </p> <pre><code>$ docker run --name container-name --env-file ./.my-pg.env -d percona/percona-distribution-postgresql:&lt;tag&gt;-multi\n</code></pre> </li> </ol> </li> <li> <p>Connect to the container\u2019s interactive terminal: </p> <pre><code>$ docker exec -it container-name bash\n</code></pre> <p>The <code>container-name</code> is the name of the container that you started in the previous step.</p> </li> </ol>"},{"location":"docker.html#connect-to-percona-distribution-for-postgresql-from-an-application-in-another-docker-container","title":"Connect to Percona Distribution for PostgreSQL from an application in another Docker container","text":"<p>This image exposes the standard PostgreSQL port (<code>5432</code>), so container linking makes the instance available to other containers. Start other containers like this in order to link it to the Percona Distribution for PostgreSQL container:</p> <pre><code>$ docker run --name app-container-name --network container:container-name -d app-that-uses-postgresql \n</code></pre> <p>where:</p> <ul> <li><code>app-container-name</code> is the name of the container where your application is running, </li> <li><code>container name</code> is the name of your Percona Distribution for PostgreSQL container, and </li> <li><code>app-that-uses-postgresql</code> is the name of your PostgreSQL client.</li> </ul>"},{"location":"docker.html#connect-to-percona-distribution-for-postgresql-from-the-psql-command-line-client","title":"Connect to Percona Distribution for PostgreSQL from the <code>psql</code> command line client","text":"<p>The following command starts another container instance and runs the <code>psql</code> command line client against your original container, allowing you to execute SQL statements against your database:</p> <pre><code>$ docker run -it --network container:db-container-name --name container-name percona/percona-distribution-postgresql:&lt;tag&gt;-multi psql -h address -U postgres\n</code></pre> <p>Where:</p> <ul> <li><code>db-container-name</code> is the name of your database container</li> <li><code>container-name</code> is the name of your container that you will use to connect to the database container using the <code>psql</code> command line client <code>tag-multi</code> is the tag specifying the version you need. For example, <code>16.2-multi</code>. The <code>multi</code> part of the tag serves to identify the architecture (x86_64 or ARM64) and pull the respective image. </li> <li><code>address</code> is the network address where your database container is running. Use 127.0.0.1, if the database container is running on the local machine/host.   </li> </ul>"},{"location":"docker.html#enable-pg_stat_monitor","title":"Enable <code>pg_stat_monitor</code>","text":"<p>To enable the <code>pg_stat_monitor</code> extension after launching the container, do the following:</p> <ul> <li>connect to the server, </li> <li>select the desired database and enable the <code>pg_stat_monitor</code> view for that database:</li> </ul> <pre><code>create extension pg_stat_monitor;\n</code></pre> <ul> <li>to ensure that everything is set up correctly, run:</li> </ul> <pre><code>\\d pg_stat_monitor;\n</code></pre> Output <pre><code>                         View \"public.pg_stat_monitor\"\n      Column        |           Type           | Collation | Nullable | Default\n---------------------+--------------------------+-----------+----------+---------\nbucket              | integer                  |           |          |\nbucket_start_time   | timestamp with time zone |           |          |\nuserid              | oid                      |           |          |\ndbid                | oid                      |           |          |\nqueryid             | text                     |           |          |\nquery               | text                     |           |          |\nplan_calls          | bigint                   |           |          |\nplan_total_time     | numeric                  |           |          |\nplan_min_timei      | numeric                  |           |          |\nplan_max_time       | numeric                  |           |          |\nplan_mean_time      | numeric                  |           |          |\nplan_stddev_time    | numeric                  |           |          |\nplan_rows           | bigint                   |           |          |\ncalls               | bigint                   |           |          |\ntotal_time          | numeric                  |           |          |\nmin_time            | numeric                  |           |          |\nmax_time            | numeric                  |           |          |\nmean_time           | numeric                  |           |          |\nstddev_time         | numeric                  |           |          |\nrows                | bigint                   |           |          |\nshared_blks_hit     | bigint                   |           |          |\nshared_blks_read    | bigint                   |           |          |\nshared_blks_dirtied | bigint                   |           |          |\nshared_blks_written | bigint                   |           |          |\nlocal_blks_hit      | bigint                   |           |          |\nlocal_blks_read     | bigint                   |           |          |\nlocal_blks_dirtied  | bigint                   |           |          |\nlocal_blks_written  | bigint                   |           |          |\ntemp_blks_read      | bigint                   |           |          |\ntemp_blks_written   | bigint                   |           |          |\nblk_read_time       | double precision         |           |          |\nblk_write_time      | double precision         |           |          |\nhost                | bigint                   |           |          |\nclient_ip           | inet                     |           |          |\nresp_calls          | text[]                   |           |          |\ncpu_user_time       | double precision         |           |          |\ncpu_sys_time        | double precision         |           |          |\ntables_names        | text[]                   |           |          |\nwait_event          | text                     |           |          |\nwait_event_type     | text                     |           |          |\n</code></pre> <p>Note that the <code>pg_stat_monitor</code> view is available only for the databases where you enabled it. If you create a new database, make sure to create the view for it to see its statistics data.</p>"},{"location":"docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"enable-extensions.html","title":"Enable Percona Distribution for PostgreSQL extensions","text":"<p>Some extensions require additional configuration before using them with Percona Distribution for PostgreSQL. This sections provides configuration instructions per extension.</p> <p>Patroni</p> <p>Patroni is the third-party high availability solution for PostgreSQL. The High Availability in PostgreSQL with Patroni chapter provides details about the solution overview and architecture deployment. </p> <p>While setting up a high availability PostgreSQL cluster with Patroni, you will need the following components:</p> <ul> <li> <p>Patroni installed on every <code>postresql</code> node. </p> </li> <li> <p>Distributed Configuration Store (DCS). Patroni supports such DCSs as ETCD, zookeeper, Kubernetes though ETCD is the most popular one. It is available upstream as DEB packages for Debian 10, 11, 12 and Ubuntu 20.04, 22.04.  </p> <p>For CentOS 8, RPM packages for ETCD is available within Percona Distribution for PostreSQL.  You can install it using the following command: </p> <pre><code>$ sudo yum install etcd python3-python-etcd\n</code></pre> </li> <li> <p>HAProxy.</p> </li> </ul> <p>See the configuration guidelines for Debian and Ubuntu and RHEL and CentOS. </p> <p>See also</p> <ul> <li> <p>Patroni documentation</p> </li> <li> <p>Percona Blog: </p> <ul> <li>PostgreSQL HA with Patroni: Your Turn to Test Failure Scenarios </li> </ul> </li> </ul> <p>pgBadger</p> <p>Enable the following options in <code>postgresql.conf</code> configuration file before starting the service:</p> <pre><code>log_min_duration_statement = 0\nlog_line_prefix = '%t [%p]: '\nlog_checkpoints = on\nlog_connections = on\nlog_disconnections = on\nlog_lock_waits = on\nlog_temp_files = 0\nlog_autovacuum_min_duration = 0\nlog_error_verbosity = default\n</code></pre> <p>For details about each option, see pdBadger documentation.</p> <p>pgAudit set-user</p> <p>Add the <code>set-user</code> to <code>shared_preload_libraries</code> in <code>postgresql.conf</code>. The recommended way is to use the ALTER SYSTEM command. Connect to psql and use the following command:</p> <pre><code>ALTER SYSTEM SET shared_preload_libraries = 'set-user';\n</code></pre> <p>Start / restart the server to apply the configuration.</p> <p>You can fine-tune user behavior with the custom parameters supplied with the extension.</p> <p>wal2json</p> <p>After the installation, enable the following option in <code>postgresql.conf</code> configuration file before starting the service:</p> <pre><code>wal_level = logical\n</code></pre>"},{"location":"enable-extensions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"extensions.html","title":"Extensions","text":"<p>Percona Distribution for PostgreSQL includes a set of extensions that have been tested to work together. These extensions enable you to efficiently solve essential practical tasks to operate and manage PostgreSQL.</p> <p>The set of extensions includes the following:</p> <ul> <li>PostgreSQL contrib modules and utilities</li> <li>Third-party components</li> <li> <p>Extensions authored by Percona:</p> <ul> <li><code>pg_stat_monitor</code></li> <li><code>pg_tde</code> </li> </ul> </li> <li> <p>Extra modules, not included in Percona Distribution for PostgreSQL but tested to work with it and supported by Percona</p> </li> </ul>"},{"location":"extensions.html#install-an-extension","title":"Install an extension","text":"<p>To use an extension, install it. Run the <code>CREATE EXTENSION</code> command on the PostgreSQL node where you want the extension to be available. </p> <p>The user should be a superuser or have the <code>CREATE</code> privilege on the current database to be able to run the <code>CREATE EXTENSION</code> command. Some extensions may require additional privileges depending on their functionality. To learn more, check the documentation for the desired extension.</p>"},{"location":"extensions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"installing.html","title":"Install Percona Distribution for PostgreSQL","text":"<p>Percona Distribution for PostgreSQL is the solution with the collection of tools from PostgreSQL community that are tested to work together and serve to assist you in deploying and managing PostgreSQL. Read more  .</p> <p>You can select from multiple easy-to-follow installation options, but we recommend using a Package Manager for a convenient and quick way to try the software first.</p> Package managerDockerKubernetes <p>Percona provides installation packages in <code>DEB</code> and <code>RPM</code> format for 64-bit Linux distributions. Find the full list of supported platforms and versions on the Percona Software and Platform Lifecycle page.</p> <p>If you are on Debian or Ubuntu, use <code>apt</code> for installation.</p> <p>If you are on Red Hat Enterprise Linux or compatible derivatives, use <code>yum</code>.</p> <p>Install via apt  Install via yum </p> <p>Choose your package manager below to get access to a detailed step-by-step guide.</p> <p>Get our image from Docker Hub and spin up a cluster on a Docker container for quick evaluation.</p> <p>Check below to get access to a detailed step-by-step guide.</p> <p>Run in Docker</p> <p>Percona Operator for Kubernetes is a controller introduced to simplify complex deployments that require meticulous and secure database expertise.</p> <p>Check below to get access to a detailed step-by-step guide.</p> <p>Get started with Percona Operator</p>"},{"location":"installing.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"ldap.html","title":"LDAP Authentication","text":"<p>When a client application or a user that runs the client application connects to the database, it must identify themselves. The process of validating the client\u2019s identity and determining whether this client is permitted to access the database it has requested is called authentication. </p> <p>Percona Distribution for PortgreSQL supports several authentication methods, including the LDAP authentication. The use of LDAP is to provide a central place for authentication - meaning the LDAP server stores usernames and passwords and their resource permissions. </p> <p>The LDAP authentication in Percona Distribution for PortgreSQL is implemented the same way as in upstream PostgreSQL.</p>"},{"location":"ldap.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"licensing.html","title":"Copyright and licensing information","text":"<p>Percona Distribution for PostgreSQL is licensed under the PostgreSQL license and licenses of all components included in the Distribution.</p>"},{"location":"licensing.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona Distribution for PostgreSQL documentation is (C)2009-2023 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License.</p>"},{"location":"licensing.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"major-upgrade.html","title":"Upgrading Percona Distribution for PostgreSQL from 15 to 16","text":"<p>This document describes the in-place upgrade of Percona Distribution for PostgreSQL using the <code>pg_upgrade</code> tool.</p> <p>The in-place upgrade means installing a new version without removing the old version and keeping the data files on the server.</p> <p>See also</p> <p><code>pg_upgrade</code> Documentation</p> <p>Similar to installing, we recommend you to upgrade Percona Distribution for PostgreSQL from Percona repositories.</p> <p>Important</p> <p>A major upgrade is a risky process because of many changes between versions and issues that might occur during or after the upgrade. Therefore, make sure to back up your data first. The backup tools are out of scope of this document. Use the backup tool of your choice.</p> <p>The general in-place upgrade flow for Percona Distribution for PostgreSQL is the following:</p> <ol> <li> <p>Install new version of Percona Distribution for PostgreSQL packages.</p> </li> <li> <p>Stop the PostgreSQL service.</p> </li> <li> <p>Check the upgrade without modifying the data.</p> </li> <li> <p>Upgrade Percona Distribution for PostgreSQL.</p> </li> <li> <p>Start PostgreSQL service.</p> </li> <li> <p>Execute the  analyze_new_cluster.sh script to generate statistics so the system is usable.</p> </li> <li> <p>Delete old packages and configuration files.</p> </li> </ol> <p>The exact steps may differ depending on the package manager of your operating system.</p>"},{"location":"major-upgrade.html#on-debian-and-ubuntu-using-apt","title":"On Debian and Ubuntu using <code>apt</code>","text":"<p>Important</p> <p>Run all commands as root or via sudo.</p> <ol> <li> <p>Install Percona Distribution for PostgreSQL 16 packages.</p> <ul> <li> <p>Install percona-release</p> </li> <li> <p>Enable Percona repository:</p> </li> </ul> <pre><code>$ sudo percona-release setup ppg-16\n</code></pre> <ul> <li>Install Percona Distribution for PostgreSQL 16 package:</li> </ul> <pre><code>$ sudo apt install percona-postgresql-16\n</code></pre> </li> <li> <p>Stop the <code>postgresql</code> service.</p> <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> <p>This stops both Percona Distribution for PostgreSQL 15 and 16.</p> </li> <li> <p>Run the database upgrade.</p> <ul> <li>Log in as the <code>postgres</code> user.</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Change the current directory to the <code>tmp</code> directory where logs and some scripts will be recorded:</li> </ul> <pre><code>$ cd tmp/\n</code></pre> <ul> <li>Check the ability to upgrade Percona Distribution for PostgreSQL from 15 to 16:</li> </ul> <pre><code>$ /usr/lib/postgresql/16/bin/pg_upgrade \\\n--old-datadir=/var/lib/postgresql/15/main \\\n--new-datadir=/var/lib/postgresql/16/main  \\\n--old-bindir=/usr/lib/postgresql/15/bin  \\\n--new-bindir=/usr/lib/postgresql/16/bin  \\\n--old-options '-c config_file=/etc/postgresql/15/main/postgresql.conf' \\\n--new-options '-c config_file=/etc/postgresql/16/main/postgresql.conf' \\\n--check\n</code></pre> <p>The <code>--check</code> flag here instructs <code>pg_upgrade</code> to only check the upgrade without changing any data.</p> <p>Sample output</p> <pre><code>Performing Consistency Checks\n-----------------------------\nChecking cluster versions                                   ok\nChecking database user is the install user                  ok\nChecking database connection settings                       ok\nChecking for prepared transactions                          ok\nChecking for reg* data types in user tables                 ok\nChecking for contrib/isn with bigint-passing mismatch       ok\nChecking for tables WITH OIDS                               ok\nChecking for invalid \"sql_identifier\" user columns          ok\nChecking for presence of required libraries                 ok\nChecking database user is the install user                  ok\nChecking for prepared transactions                          ok\n\n*Clusters are compatible*\n</code></pre> <ul> <li>Upgrade the Percona Distribution for PostgreSQL</li> </ul> <pre><code>$ /usr/lib/postgresql/16/bin/pg_upgrade \\\n--old-datadir=/var/lib/postgresql/15/main \\\n--new-datadir=/var/lib/postgresql/16/main  \\\n--old-bindir=/usr/lib/postgresql/15/bin  \\\n--new-bindir=/usr/lib/postgresql/16/bin  \\\n--old-options '-c config_file=/etc/postgresql/15/main/postgresql.conf' \\\n--new-options '-c config_file=/etc/postgresql/16/main/postgresql.conf' \\\n--link\n</code></pre> <p>The  <code>--link</code> flag creates hard links to the files on the old version cluster so you don\u2019t need to copy data.</p> <p>If you don\u2019t wish to use the <code>--link</code> option, make sure that you have enough disk space to store 2 copies of files for both old version and new version clusters.</p> <ul> <li>Go back to the regular user:</li> </ul> <pre><code>$ exit\n</code></pre> <ul> <li>The Percona Distribution for PostgreSQL 15 uses the <code>5432</code> port while the Percona Distribution for PostgreSQL 16 is set up to use the <code>5433</code> port by default. To start the Percona Distribution for PostgreSQL 15, swap ports in the configuration files of both versions.</li> </ul> <pre><code>$ sudo vim /etc/postgresql/16/main/postgresql.conf\n$ port = 5433 # Change to 5432 here\n$ sudo vim /etc/postgresql/15/main/postgresql.conf\n$ port = 5432 # Change to 5433 here\n</code></pre> </li> <li> <p>Start the <code>postgreqsl</code> service.</p> <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> </li> <li> <p>Check the <code>postgresql</code> version.</p> <ul> <li>Log in as a postgres user</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Check the database version</li> </ul> <pre><code>$ psql -c \"SELECT version();\"\n</code></pre> </li> <li> <p>After the upgrade, the Optimizer statistics are not transferred to the new cluster. Run the <code>vaccumdb</code> command to analyze the new cluster:</p> <pre><code>$ /usr/lib/postgresql/16/bin/vacuumdb --all --analyze-in-stages\n</code></pre> </li> <li> <p>Delete the old cluster\u2019s data files:</p> <pre><code>$ ./delete_old_cluster.sh\n$ sudo rm -rf /etc/postgresql/15/main\n$ #Logout\n$ exit\n</code></pre> </li> </ol>"},{"location":"major-upgrade.html#on-red-hat-enterprise-linux-and-centos-using-yum","title":"On Red Hat Enterprise Linux and CentOS using <code>yum</code>","text":"<p>Important</p> <p>Run all commands as root or via sudo.</p> <ol> <li> <p>Install Percona Distribution for PostgreSQL 16 packages</p> <ul> <li> <p>Install percona-release</p> </li> <li> <p>Enable Percona repository:</p> </li> </ul> <pre><code>$ sudo percona-release setup ppg-16\n</code></pre> <ul> <li>Install Percona Distribution for PostgreSQL 16:</li> </ul> <pre><code>$ sudo yum install percona-postgresql16-server\n</code></pre> </li> <li> <p>Set up Percona Distribution for PostgreSQL 16 cluster</p> </li> <li> <p>Log is as the postgres user</p> <pre><code>$ sudo su postgres\n</code></pre> </li> <li> <p>Set up locale settings</p> <pre><code>export LC_ALL=\"en_US.UTF-8\"\nexport LC_CTYPE=\"en_US.UTF-8\"\n</code></pre> </li> <li> <p>Initialize cluster with the new data directory</p> <pre><code>$ /usr/pgsql-16/bin/initdb -D /var/lib/pgsql/16/data\n</code></pre> </li> <li> <p>Stop the <code>postgresql</code> 15 service</p> <pre><code>$ systemctl stop postgresql-15\n</code></pre> </li> <li> <p>Run the database upgrade.</p> <ul> <li>Log in as the <code>postgres</code> user</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Check the ability to upgrade Percona Distribution for PostgreSQL from 15 to 16:</li> </ul> <pre><code>$ /usr/pgsql-16/bin/pg_upgrade \\\n--old-bindir /usr/pgsql-15/bin \\\n--new-bindir /usr/pgsql-16/bin  \\\n--old-datadir /var/lib/pgsql/15/data \\\n--new-datadir /var/lib/pgsql/16/data \\\n--check\n</code></pre> <p>The <code>--check</code> flag here instructs <code>pg_upgrade</code> to only check the upgrade without changing any data.</p> <p>Sample output</p> <pre><code>Performing Consistency Checks\n-----------------------------\nChecking cluster versions                                   ok\nChecking database user is the install user                  ok\nChecking database connection settings                       ok\nChecking for prepared transactions                          ok\nChecking for reg* data types in user tables                 ok\nChecking for contrib/isn with bigint-passing mismatch       ok\nChecking for tables WITH OIDS                               ok\nChecking for invalid \"sql_identifier\" user columns          ok\nChecking for presence of required libraries                 ok\nChecking database user is the install user                  ok\nChecking for prepared transactions                          ok\n\n*Clusters are compatible*\n</code></pre> <ul> <li>Upgrade the Percona Distribution for PostgreSQL</li> </ul> <pre><code>$ /usr/pgsql-16/bin/pg_upgrade \\\n--old-bindir /usr/pgsql-15/bin \\\n--new-bindir /usr/pgsql-16/bin  \\\n--old-datadir /var/lib/pgsql/15/data \\\n--new-datadir /var/lib/pgsql/16/data \\\n--link \n</code></pre> <p>The  <code>--link</code> flag creates hard links to the files on the old version cluster so you don\u2019t need to copy data.    If you don\u2019t wish to use the <code>--link</code> option, make sure that you have enough disk space to store 2 copies of files for both old version and new version clusters.</p> </li> <li> <p>Start the <code>postgresql</code> 16 service.</p> <pre><code>$ systemctl start postgresql-16\n</code></pre> </li> <li> <p>Check postgresql status</p> <pre><code>$ systemctl status postgresql-16\n</code></pre> </li> <li> <p>After the upgrade, the Optimizer statistics are not transferred to the new cluster. Run the <code>vaccumdb</code> command to analyze the new cluster:</p> <ul> <li>Log in as the postgres user</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Run the script to analyze the new cluster:</li> </ul> <pre><code>$ /usr/pgsql-16/bin/vacuumdb --all --analyze-in-stages\n</code></pre> </li> <li> <p>Delete Percona Distribution for PostgreSQL 15 configuration files</p> <pre><code>$ ./delete_old_cluster.sh\n</code></pre> </li> <li> <p>Delete Percona Distribution old data files</p> <pre><code>$ rm -rf /var/lib/pgsql/15/data\n</code></pre> </li> </ol>"},{"location":"major-upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"migration.html","title":"Migrate from PostgreSQL to Percona Distribution for PostgreSQL","text":"<p>Percona Distribution for PostgreSQL includes the PostgreSQL database and additional extensions that have been selected to cover the needs of the enterprise and are guaranteed to work together. Percona Distribution for PostgreSQL is available as a software collection that is easy to deploy.</p> <p>We encourage users to migrate from their PostgreSQL deployments based on community binaries to Percona Distribution for PostgreSQL. This document provides the migration instructions. </p> <p>Depending on your business requirements, you may migrate to Percona Distribution for PostgreSQL either on the same server or onto a different server. </p>"},{"location":"migration.html#migrate-on-the-same-server","title":"Migrate on the same server","text":"On Debian and Ubuntu LinuxOn RHEL and derivatives <p>To ensure that your data is safe during the migration, we recommend to make a backup of your data and all configuration files (such as <code>pg_hba.conf</code>, <code>postgresql.conf</code>, <code>postgresql.auto.conf</code>) using the tool of your choice. The backup process is out of scope of this document. You can use <code>pg_dumpall</code> or other tools of your choice. </p> <ol> <li> <p>Stop the <code>postgresql</code> server   </p> <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> </li> <li> <p>Remove community packages</p> <pre><code>$ sudo apt-get --purge remove postgresql\n</code></pre> </li> <li> <p>Install percona-release</p> </li> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages</p> </li> <li>(Optional) Restore the data from the backup.</li> <li> <p>Start the <code>postgresql</code> service. The installation process starts and initializes the default cluster automatically. You can check its status with: </p> <pre><code>$ sudo systemctl status postgresql\n</code></pre> <p>If <code>postresql</code> service is not started, start it manually:</p> <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> </li> </ol> <p>To ensure that your data is safe during the migration, we recommend to make a backup of your data and all configuration files (such as <code>pg_hba.conf</code>, <code>postgresql.conf</code>, <code>postgresql.auto.conf</code>) using the tool of your choice. The backup process is out of scope of this document. You can use <code>pg_dumpall</code> or other tools of your choice. </p> <ol> <li> <p>Stop the <code>postgresql</code> server   </p> <pre><code>$ sudo systemctl stop postgresql-16\n</code></pre> </li> <li> <p>Remove community packages</p> <pre><code>$ sudo yum remove postgresql\n</code></pre> </li> <li> <p>Install percona-release</p> </li> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages</p> </li> <li>(Optional) Restore the data from the backup.</li> <li> <p>Start the <code>postgresql</code> service</p> <pre><code>$ sudo systemctl start postgresql-16\n</code></pre> </li> </ol>"},{"location":"migration.html#migrate-on-a-different-server","title":"Migrate on a different server","text":"<p>In this scenario, we will refer to the server with PostgreSQL Community as the \u201csource\u201d and to the server with Percona Distribution for PostgreSQL as the \u201ctarget\u201d.</p> <p>To migrate from PostgreSQL Community to Percona Distribution for PostgreSQL on a different server, do the following:</p> <p>On the source server:</p> <ol> <li>Back up your data and all configuration files (such as <code>pg_hba.conf</code>, <code>postgresql.conf</code>, <code>postgresql.auto.conf</code>) using the tool of your choice.</li> <li> <p>Stop the <code>postgresql</code> service</p> On Debian and UbuntuOn RHEL and derivatives <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> <pre><code>$ sudo systemctl stop postgresql-16\n</code></pre> </li> <li> <p>Optionally, remove PostgreSQL Community packages </p> </li> </ol> <p>On the target server:</p> <ol> <li>Install percona-release </li> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages on the target server.</p> </li> <li>Restore the data from the backup</li> <li> <p>Start <code>postgresql</code> service</p> On Debian and UbuntuOn RHEL and derivatives <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> <pre><code>$ sudo systemctl start postgresql-16\n</code></pre> </li> </ol>"},{"location":"migration.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"minor-upgrade.html","title":"Minor Upgrade of Percona Distribution for PostgreSQL","text":"<p>Minor releases of PostgreSQL include bug fixes and feature enhancements. We recommend that you keep your Percona Distribution for PostgreSQL updated to the latest minor version.</p> <p>Though minor upgrades do not change the behavior, we recommend you to back up your data first, in order to be on the safe side.</p> <p>Minor upgrade of Percona Distribution for PostgreSQL includes the following steps:</p> <ol> <li> <p>Stop the <code>postgresql</code> cluster;</p> </li> <li> <p>Install new version packages;</p> </li> <li> <p>Restart the <code>postgresql</code> cluster.</p> </li> </ol> <p>Note</p> <p>These steps apply if you installed Percona Distribution for PostgreSQL from the Major Release repository. In this case, you are always upgraded to the latest available release.</p> <p>If you installed Percona Distribution for PostgreSQL from the Minor Release repository, you will need to enable a new version repository to upgrade.</p> <p>For more information about Percona repositories, refer to Installing Percona Distribution for PostgreSQL.</p> <p>Before the upgrade, update the <code>percona-release</code> utility to the latest version. This is required to install the new version packages of Percona Distribution for PostgreSQL. </p> <p>Important</p> <p>Run all commands as root or via sudo.</p> <ol> <li> <p>Stop the <code>postgresql</code> service.</p> On Debian / UbuntuOn Red Hat Enterprise Linux / derivatives <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> <pre><code>$ sudo systemctl stop postgresql-16\n</code></pre> </li> <li> <p>Install new version packages. See Installing Percona Distribution for PostgreSQL.</p> </li> <li> <p>Restart the <code>postgresql</code> service.</p> On Debian / UbuntuOn Red Hat Enterprise Linux / derivatives <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> <pre><code>$ sudo systemctl start postgresql-16\n</code></pre> </li> </ol> <p>If you wish to upgrade Percona Distribution for PostgreSQL to the major version, refer to Upgrading Percona Distribution for PostgreSQL from 15 to 16.</p>"},{"location":"minor-upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pg-stat-monitor.html","title":"pg_stat_monitor","text":"<p>Note</p> <p>This document describes the functionality of pg_stat_monitor 2.0.2.</p>"},{"location":"pg-stat-monitor.html#overview","title":"Overview","text":"<p><code>pg_stat_monitor</code> is a  Query Performance Monitoring tool for PostgreSQL. It collects various statistics data such as query statistics, query plan, SQL comments and other performance insights. The collected data is aggregated and presented in a single view. This allows you to view queries from performance, application and analysis perspectives.</p> <p><code>pg_stat_monitor</code> groups statistics data and writes it in a storage unit called bucket. The data is added and stored in a bucket for the defined period \u2013 the bucket lifetime. This allows you to identify performance issues and patterns based on time.</p> <p>You can specify the following:</p> <ul> <li>The number of buckets. Together they form a bucket chain.</li> <li>Bucket size. This is the amount of shared memory allocated for buckets. Memory is divided equally among buckets.</li> <li>Bucket lifetime.</li> </ul> <p>When a bucket lifetime expires, <code>pg_stat_monitor</code> resets all statistics and writes the data in the next bucket in the chain. When the last bucket\u2019s lifetime expires, <code>pg_stat_monitor</code> returns to the first bucket.</p> <p>Important</p> <p>The contents of the bucket will be overwritten. In order not to lose the data, make sure to read the bucket before <code>pg_stat_monitor</code> starts writing new data to it.</p>"},{"location":"pg-stat-monitor.html#views","title":"Views","text":""},{"location":"pg-stat-monitor.html#pg_stat_monitor-view","title":"pg_stat_monitor view","text":"<p>The <code>pg_stat_monitor</code> view contains all the statistics collected and aggregated by the extension. This view contains one row for each distinct combination of metrics and whether it is a top-level statement or not (up to the maximum number of distinct statements that the module can track). For details about available metrics, refer to the <code>pg_stat_monitor</code> view reference.</p> <p>The following are the primary keys for pg_stat_monitor:</p> <ul> <li><code>bucket</code></li> <li><code>userid</code></li> <li><code>datname</code></li> <li><code>queryid</code></li> <li><code>client_ip</code></li> <li><code>planid</code></li> <li><code>application_name</code></li> </ul> <p>A new row is created for each key in the <code>pg_stat_monitor</code> view.</p> <p>For security reasons, only superusers and members of the <code>pg_read_all_stats</code> role are allowed to see the SQL text, <code>client_ip</code> and <code>queryid</code> of queries executed by other users. Other users can see the statistics, however, if the view has been installed in their database.</p>"},{"location":"pg-stat-monitor.html#pg_stat_monitor_settings-view-dropped","title":"pg_stat_monitor_settings view (dropped)","text":"<p>Starting with version 2.0.0, the <code>pg_stat_monitor_settings</code> view is deprecated and removed. All <code>pg_stat_monitor</code> configuration parameters are now available though the <code>pg_settings</code> view using the following query: </p> <pre><code>SELECT name, setting, unit, context, vartype, source, min_val, max_val, enumvals, boot_val, reset_val, pending_restart FROM pg_settings WHERE name LIKE '%pg_stat_monitor%';\n</code></pre> <p>For backward compatibility, you can create the <code>pg_stat_monitor_settings</code> view using the following SQL statement:</p> <pre><code>CREATE VIEW pg_stat_monitor_settings\n\nAS\n\nSELECT *\n\nFROM pg_settings\n\nWHERE name like 'pg_stat_monitor.%';\n</code></pre> <p>In <code>pg_stat_monitor</code> version 1.1.1 and earlier, the <code>pg_stat_monitor_settings</code> view shows one row per <code>pg_stat_monitor</code> configuration parameter. It displays configuration parameter name, value, default value, description, minimum and maximum values, and whether a restart is required for a change in value to be effective.</p> <p>To learn more, see the Changing the configuration section.</p>"},{"location":"pg-stat-monitor.html#installation","title":"Installation","text":"<p>This section describes how to install <code>pg_stat_monitor</code> from Percona repositories. To learn about other installation methods, see the Installation section in the <code>pg_stat_monitor</code> documentation.</p> <p>Preconditions:</p> <p>To install <code>pg_stat_monitor</code> from Percona repositories, you need to subscribe to them. To do this, you must have the <code>percona-release</code> repository management tool up and running. </p> <p>To install <code>pg_stat_monitor</code>, run the following commands:</p> On Debian and UbuntuOn Red Hat Enterprise Linux and derivatives <ol> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install the package:</p> <pre><code>$ sudo apt-get install percona-pg-stat-monitor16\n</code></pre> </li> </ol> <ol> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install the package:</p> <pre><code>$ sudo yum install percona-pg-stat-monitor16\n</code></pre> </li> </ol>"},{"location":"pg-stat-monitor.html#setup","title":"Setup","text":"<p><code>pg_stat_monitor</code> requires additional setup in order to use it with PostgreSQL. The setup steps are the following:</p> <ol> <li> <p>Add <code>pg_stat_monitor</code> in the <code>shared_preload_libraries</code> configuration parameter.</p> <p>The recommended way to modify PostgreSQL configuration file is using the ALTER SYSTEM command. Connect to psql and use the following command:</p> <pre><code>ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_monitor';\n</code></pre> <p>The parameter value is written to the <code>postgresql.auto.conf</code> file which is read in addition with <code>postgresql.conf</code> file.</p> <p>Note</p> <p>To use <code>pg_stat_monitor</code> together with <code>pg_stat_statements</code>, specify both modules separated by commas for the <code>ALTER SYSTEM SET</code> command. </p> <p>The order of modules is important: <code>pg_stat_monitor</code> must be specified after <code>pg_stat_statements</code>: </p> <pre><code>ALTER SYSTEM SET shared_preload_libraries = \u2018pg_stat_statements, pg_stat_monitor\u2019\n</code></pre> </li> <li> <p>Start or restart the <code>postgresql</code> instance to enable <code>pg_stat_monitor</code>. Use the following command for restart:</p> On Debian and UbuntuOn Red Hat Enterprise Linux and derivatives <pre><code>$ sudo systemctl restart postgresql.service\n</code></pre> <pre><code>$ sudo systemctl restart postgresql-16\n</code></pre> </li> <li> <p>Create the extension. Connect to <code>psql</code> and use the following command:</p> <pre><code>CREATE EXTENSION pg_stat_monitor;\n</code></pre> <p>By default, the extension is created against the <code>postgres</code> database. You need to create the extension on every database where you want to collect statistics.</p> </li> </ol> <p>Tip</p> <p>To check the version of the extension, run the following command in the <code>psql</code> session:</p> <pre><code>SELECT pg_stat_monitor_version();\n</code></pre>"},{"location":"pg-stat-monitor.html#usage","title":"Usage","text":"<p>For example, to view the IP address of the client application that made the query, run the following command:</p> <pre><code>SELECT DISTINCT userid::regrole, pg_stat_monitor.datname, substr(query,0, 50) AS query, calls, bucket, bucket_start_time, queryid, client_ip\nFROM pg_stat_monitor, pg_database\nWHERE pg_database.oid = oid;\n</code></pre> <p>Output:</p> <pre><code>  userid  | datname  |                       query                       | calls | bucket |  bucket_start_time  |     queryid      | client_ip\n----------+----------+---------------------------------------------------+-------+--------+---------------------+------------------+-----------\n postgres | postgres | SELECT name,description FROM pg_stat_monitor_sett |     1 |      9 | 2022-10-24 07:29:00 | AD536A8DEA7F0C73 | 127.0.0.1\n postgres | postgres | SELECT c.oid,                                    +|     1 |      9 | 2022-10-24 07:29:00 | 34B888E5C844519C | 127.0.0.1\n          |          |   n.nspname,                                     +|       |        |                     |                  |\n          |          |   c.relname                                      +|       |        |                     |                  |\n          |          | FROM pg_ca                                        |       |        |                     |                  |\n postgres | postgres | SELECT DISTINCT userid::regrole, pg_stat_monitor. |     1 |      1 | 2022-10-24 07:31:00 | 6230793895381F1D | 127.0.0.1\n postgres | postgres | SELECT pg_stat_monitor_version()                  |     1 |      9 | 2022-10-24 07:29:00 | B617F5F12931F388 | 127.0.0.1\n postgres | postgres | CREATE EXTENSION pg_stat_monitor                  |     1 |      8 | 2022-10-24 07:28:00 | 14B98AF0776BAF7B | 127.0.0.1\n postgres | postgres | SELECT a.attname,                                +|     1 |      9 | 2022-10-24 07:29:00 | 96F8E4B589EF148F | 127.0.0.1\n          |          |   pg_catalog.format_type(a.attt                   |       |        |                     |                  |\n postgres | postgres | SELECT c.relchecks, c.relkind, c.relhasindex, c.r |     1 |      9 | 2022-10-24 07:29:00 | CCC51D018AC96A25 | 127.0.0.1\n</code></pre> <p>Find more usage examples in the <code>pg_stat_monitor</code> user guide.</p>"},{"location":"pg-stat-monitor.html#changing-the-configuration","title":"Changing the configuration","text":"<p>Run the following query to list available configuration parameters.</p> <pre><code>SELECT name, short_desc FROM pg_settings WHERE name LIKE '%pg_stat_monitor%';\n</code></pre> <p>Output</p> <pre><code>                   name                    |                                                           short_desc\n-------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------\n pg_stat_monitor.pgsm_bucket_time          | Sets the time in seconds per bucket.\n pg_stat_monitor.pgsm_enable_overflow      | Enable/Disable pg_stat_monitor to grow beyond shared memory into swap space.\n pg_stat_monitor.pgsm_enable_pgsm_query_id | Enable/disable PGSM specific query id calculation which is very useful in comparing same query across databases and clusters..\n pg_stat_monitor.pgsm_enable_query_plan    | Enable/Disable query plan monitoring.\n pg_stat_monitor.pgsm_extract_comments     | Enable/Disable extracting comments from queries.\n pg_stat_monitor.pgsm_histogram_buckets    | Sets the maximum number of histogram buckets.\n pg_stat_monitor.pgsm_histogram_max        | Sets the time in millisecond.\n pg_stat_monitor.pgsm_histogram_min        | Sets the time in millisecond.\n pg_stat_monitor.pgsm_max                  | Sets the maximum size of shared memory in (MB) used for statement's metadata tracked by pg_stat_monitor.\n pg_stat_monitor.pgsm_max_buckets          | Sets the maximum number of buckets.\n pg_stat_monitor.pgsm_normalized_query     | Selects whether save query in normalized format.\n pg_stat_monitor.pgsm_overflow_target      | Sets the overflow target for pg_stat_monitor. (Deprecated, use pgsm_enable_overflow)\n pg_stat_monitor.pgsm_query_max_len        | Sets the maximum length of query.\n pg_stat_monitor.pgsm_query_shared_buffer  | Sets the maximum size of shared memory in (MB) used for query tracked by pg_stat_monitor.\n pg_stat_monitor.pgsm_track                | Selects which statements are tracked by pg_stat_monitor.\n pg_stat_monitor.pgsm_track_planning       | Selects whether planning statistics are tracked.\n pg_stat_monitor.pgsm_track_utility        | Selects whether utility commands are tracked.\n</code></pre> <p>You can change a parameter by setting a new value in the configuration file. Some parameters require server restart to apply a new value. For others, configuration reload is enough. Refer to the configuration parameters of the <code>pg_stat_monitor</code> documentation for the parameters\u2019 description, how you can change their values and if the server restart is required to apply them.</p> <p>As an example, let\u2019s set the bucket lifetime from default 60 seconds to 40 seconds. Use the ALTER SYSTEM command:</p> <pre><code>ALTER SYSTEM set pg_stat_monitor.pgsm_bucket_time = 40;\n</code></pre> <p>Restart the server to apply the change:</p> On Debian and UbuntuOn Red Hat Enterprise Linux and derivatives <pre><code>$ sudo systemctl restart postgresql.service\n</code></pre> <pre><code>$ sudo systemctl restart postgresql-15\n</code></pre> <p>Verify the updated parameter:</p> <pre><code>SELECT name, setting \nFROM pg_settings \nWHERE name = 'pg_stat_monitor.pgsm_bucket_time';\n\n                 name               | setting\n  ----------------------------------+---------\n   pg_stat_monitor.pgsm_bucket_time |   40\n</code></pre> <p>See also</p> <p><code>pg_stat_monitor</code> Documentation</p> <p>Percona Blog:</p> <ul> <li>pg_stat_monitor: A New Way Of Looking At PostgreSQL Metrics</li> <li>Improve PostgreSQL Query Performance Insights with pg_stat_monitor</li> </ul>"},{"location":"pg-stat-monitor.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes-v16.0.html","title":"Percona Distribution for PostgreSQL 16.0 (2023-09-19)","text":"<p>Installation Upgrade</p> <p>We are pleased to announce the launch of Percona Distribution for PostgreSQL 16.0 - a solution with the collection of tools from PostgreSQL community that are tested to work together and serve to assist you in deploying and managing PostgreSQL. The aim of Percona Distribution for PostgreSQL is to address the operational issues like High-Availability, Disaster Recovery, Security, Observability, Spatial data handling, Performance and Scalability and others that enterprises are facing.</p> <p>This release of Percona Distribution for PostgreSQL is based on PostgreSQL 16. </p>"},{"location":"release-notes-v16.0.html#release-highlights","title":"Release Highlights","text":"<p>Percona Distribution for PostgreSQL 16 features a lot of new functionalities and enhancements to performance, replication, monitoring, developer experience and more. Among them are the following:</p> <ul> <li> <p>Performance improvements:</p> <ul> <li>The support for CPU acceleration using SIMD (Single Instruction/Multiple Data) computing method for both x86 and ARM architectures </li> <li>Optimized processing of ASCII and JSON strings and array and subtransaction searches improve query processing performance.</li> <li>The support of concurrent bulk data loading using <code>COPY</code> boost performance up to 300%.</li> <li>Load balancing for <code>libpq</code> client simplifies scaling read queries.</li> <li>The use of lz4 and zstd compression methods for <code>pg_dump</code> results in better compression performance compared to the default gzip compression method.</li> </ul> </li> <li> <p>Logical replication improvements include the ability to apply large transactions in parallel and the ability to perform logical decoding on standbys. This enables users to distribute their workloads among nodes. </p> </li> <li> <p>Developer experience:</p> <ul> <li>The standard for manipulating JSON data now includes the SQL/JSON constructors and the <code>ANY_VALUE</code> aggregate function, which returns any arbitrary value from the aggregate set. </li> <li>Developers can now specify non-decimal integers such as 0xff and 0o777.</li> <li>Added support for the extended query protocol to the  <code>psql</code> client.</li> </ul> </li> <li> <p>Privilege administration improvements:</p> <ul> <li>Logical replication subscribers now execute transactions on a table as the table owner, not the superuser.</li> <li>Now only the users that have the ADMIN OPTION for roles can grant privileges in these roles using the <code>CREATEROLE</code> function. This allows fine-tuning privileges definition.</li> <li>New predefined role <code>pg_maintain</code> enables non-superusers to run VACUUM, ANALYZE, CLUSTER, REFRESH MATERIALIZED VIEW, REINDEX, and LOCK TABLE on all tables.</li> </ul> </li> <li> <p>Database administrators can now view insights on I/O statistics in a separate <code>pg_stat_io</code> view provides. </p> </li> </ul> <p>See also</p> <ul> <li>PostgreSQL 16 release notes</li> </ul> <p>The following is the list of extensions available in Percona Distribution for PostgreSQL.</p> Extension Version Description HAProxy 2.8.2 a high-availability and load-balancing solution Patroni 3.1.0 a HA (High Availability) solution for PostgreSQL PgAudit 16.0 provides detailed session or object audit logging via the standard logging facility provided by PostgreSQL pgAudit set_user 4.0.1 provides an additional layer of logging and control when unprivileged users must escalate themselves to superusers or object owner roles in order to perform needed maintenance tasks. pgBackRest 2.47 a backup and restore solution for PostgreSQL pgBadger 12.2 a fast PostgreSQL Log Analyzer. PgBouncer 1.20.1 a lightweight connection pooler for PostgreSQL pg_gather v22 an SQL script for running the diagnostics of the health of PostgreSQL cluster pgpool2 4.4.4 a middleware between PostgreSQL server and client for high availability, connection pooling and load balancing. pg_repack 1.4.8 rebuilds PostgreSQL database objects pg_stat_monitor 2.0.2 collects and aggregates statistics for PostgreSQL and provides histogram information. PostGIS 3.3.4 a spatial extension for PostgreSQL. PostgreSQL Common 253 PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. wal2json 2.5 a PostgreSQL logical decoding JSON output plugin <p>Percona Distribution for PostgreSQL also includes the following packages:</p> <ul> <li><code>llvm</code> 12.0.1 packages for Red Hat Enterprise Linux 8 / CentOS 8. This fixes compatibility issues with LLVM from upstream.</li> <li>supplemental <code>ETCD</code> packages which can be used for setting up Patroni clusters. These packages are available for the following operating systems:</li> </ul> Operating System Package Version Description CentOS 8 <code>etcd</code> 3.3.11 A consistent, distributed key-value store <code>python3-etcd</code> 0.4.5 A Python client for ETCD <p>Percona Distribution for PostgreSQL is also shipped with the libpq library. It contains \u201ca set of library functions that allow client programs to pass queries to the PostgreSQL backend server and to receive the results of these queries.\u201d </p>"},{"location":"release-notes-v16.0.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes-v16.0.upd.html","title":"Percona Distribution for PostgreSQL 16.0 Update (2023-11-02)","text":"<p>Installation Upgrade</p> <p>This update to the release of Percona Distribution for PostgreSQL 16.0 includes the Docker images for x86_64 architectures. It aims to simplify the developers\u2019 experience with the Distribution. Refer to the Docker guide for how to run Percona Distribution for PostgreSQL in Docker.</p>"},{"location":"release-notes-v16.0.upd.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes-v16.1.html","title":"Percona Distribution for PostgreSQL 16.1 (2023-11-29)","text":"<p>Installation</p> <p>Percona Distribution for PostgreSQL is a solution with the collection of tools from PostgreSQL community that are tested to work together and serve to assist you in deploying and managing PostgreSQL. The aim of Percona Distribution for PostgreSQL is to address the operational issues like High-Availability, Disaster Recovery, Security, Observability, Spatial data handling, Performance and Scalability and others that enterprises are facing.</p> <p>This release of Percona Distribution for PostgreSQL is based on PostgreSQL 16.1. </p>"},{"location":"release-notes-v16.1.html#release-highlights","title":"Release Highlights","text":"<ul> <li>Telemetry is now enabled in Percona Distribution for PostgreSQL to fill in the gaps in our understanding of how you use it and help us improve our products. Participation in the anonymous program is optional. You can opt-out if you prefer not to share this information. Find more information in the Telemetry on Percona Distribution for PostgreSQL document.</li> <li>The <code>percona-postgis33</code> and <code>percona-pgaudit</code> packages on YUM-based operating systems are renamed <code>percona-postgis33_16</code> and <code>percona-pgaudit16</code> respectively</li> </ul> <p>The following is the list of extensions available in Percona Distribution for PostgreSQL.</p> Extension Version Description HAProxy 2.8.3 a high-availability and load-balancing solution Patroni 3.1.0 a HA (High Availability) solution for PostgreSQL PgAudit 16.1 provides detailed session or object audit logging via the standard logging facility provided by PostgreSQL pgAudit set_user 4.0.1 provides an additional layer of logging and control when unprivileged users must escalate themselves to superusers or object owner roles in order to perform needed maintenance tasks. pgBackRest 2.48 a backup and restore solution for PostgreSQL pgBadger 12.2 a fast PostgreSQL Log Analyzer. PgBouncer 1.21.0 a lightweight connection pooler for PostgreSQL pg_gather v23 an SQL script for running the diagnostics of the health of PostgreSQL cluster pgpool2 4.4.4 a middleware between PostgreSQL server and client for high availability, connection pooling and load balancing. pg_repack 1.4.8 rebuilds PostgreSQL database objects pg_stat_monitor 2.0.3 collects and aggregates statistics for PostgreSQL and provides histogram information. PostGIS 3.3.4 a spatial extension for PostgreSQL. PostgreSQL Common 256 PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. wal2json 2.5 a PostgreSQL logical decoding JSON output plugin <p>Percona Distribution for PostgreSQL also includes the following packages:</p> <ul> <li><code>llvm</code> 12.0.1 packages for Red Hat Enterprise Linux 8 and compatible derivatives. This fixes compatibility issues with LLVM from upstream.</li> <li>supplemental <code>ETCD</code> packages which can be used for setting up Patroni clusters. These packages are available for the following operating systems:</li> </ul> Operating System Package Version Description RHEL 8 <code>etcd</code> 3.3.11 A consistent, distributed key-value store <code>python3-etcd</code> 0.4.5 A Python client for ETCD <p>Percona Distribution for PostgreSQL is also shipped with the libpq library. It contains \u201ca set of library functions that allow client programs to pass queries to the PostgreSQL backend server and to receive the results of these queries.\u201d </p>"},{"location":"release-notes-v16.1.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes-v16.1.upd.html","title":"Percona Distribution for PostgreSQL 16.1 Update (2024-01-18)","text":"<p>Installation</p> <p>Percona Distribution for PostgreSQL is a solution with the collection of tools from PostgreSQL community that are tested to work together and serve to assist you in deploying and managing PostgreSQL. The aim of Percona Distribution for PostgreSQL is to address the operational issues like High-Availability, Disaster Recovery, Security, Observability, Spatial data handling, Performance and Scalability and others that enterprises are facing.</p> <p>This update of Percona Distribution for PostgreSQL includes the new version of <code>pg_stat_monitor</code> 2.0.4 that fixes the issue with the extension causing the deadlock in the Percona Operator for PostgreSQL when executing the <code>pgsm_store</code> function.</p>"},{"location":"release-notes-v16.1.upd.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes-v16.2.html","title":"Percona Distribution for PostgreSQL 16.2 (2024-02-27)","text":"<p>Installation</p> <p>Percona Distribution for PostgreSQL is a solution with the collection of tools from PostgreSQL community that are tested to work together and serve to assist you in deploying and managing PostgreSQL. The aim of Percona Distribution for PostgreSQL is to address the operational issues like High-Availability, Disaster Recovery, Security, Observability, Spatial data handling, Performance and Scalability and others that enterprises are facing.</p> <p>This release of Percona Distribution for PostgreSQL is based on PostgreSQL 16.2. </p>"},{"location":"release-notes-v16.2.html#release-highlights","title":"Release Highlights","text":"<ul> <li>A Docker image for Percona Distribution for PostgreSQL is now available for ARM architectures. This improves the user experience with the Distribution for developers with ARM-based workstations.</li> </ul> <p>The following is the list of extensions available in Percona Distribution for PostgreSQL.</p> Extension Version Description HAProxy 2.8.5 a high-availability and load-balancing solution Patroni 3.2.2 a HA (High Availability) solution for PostgreSQL PgAudit 16 provides detailed session or object audit logging via the standard logging facility provided by PostgreSQL pgAudit set_user 4.0.1 provides an additional layer of logging and control when unprivileged users must escalate themselves to superusers or object owner roles in order to perform needed maintenance tasks. pgBackRest 2.50 a backup and restore solution for PostgreSQL pgBadger 12.4 a fast PostgreSQL Log Analyzer. PgBouncer 1.22.0 a lightweight connection pooler for PostgreSQL pg_gather v25 an SQL script for running the diagnostics of the health of PostgreSQL cluster pgpool2 4.5.0 a middleware between PostgreSQL server and client for high availability, connection pooling and load balancing. pg_repack 1.5.0 rebuilds PostgreSQL database objects pg_stat_monitor 2.0.4 collects and aggregates statistics for PostgreSQL and provides histogram information. PostGIS 3.3.5 a spatial extension for PostgreSQL. PostgreSQL Common 256 PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. wal2json 2.5 a PostgreSQL logical decoding JSON output plugin <p>Percona Distribution for PostgreSQL also includes the following packages:</p> <ul> <li><code>llvm</code> 12.0.1 packages for Red Hat Enterprise Linux 8 and compatible derivatives. This fixes compatibility issues with LLVM from upstream.</li> <li>supplemental <code>ETCD</code> packages which can be used for setting up Patroni clusters. These packages are available for the following operating systems:</li> </ul> Operating System Package Version Description RHEL 8 and derivatives <code>etcd</code> 3.5.12 A consistent, distributed key-value store <code>python3-etcd</code> 0.4.5 A Python client for ETCD <p>Percona Distribution for PostgreSQL is also shipped with the libpq library. It contains \u201ca set of library functions that allow client programs to pass queries to the PostgreSQL backend server and to receive the results of these queries.\u201d </p>"},{"location":"release-notes-v16.2.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes.html","title":"Percona Distribution for PostgreSQL release notes","text":"<ul> <li> <p>Percona Distribution for PostgreSQL 16.2 (2024-02-27)</p> </li> <li> <p>Percona Distribution for PostgreSQL 16.1 Update (2024-01-18)</p> </li> <li> <p>Percona Distribution for PostgreSQL 16.1 (2023-11-29)</p> </li> <li> <p>Percona Distribution for PostgreSQL 16.0 Update (2023-11-02)</p> </li> <li> <p>Percona Distribution for PostgreSQL 16 (2023-09-19)</p> </li> </ul>"},{"location":"release-notes.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"repo-overview.html","title":"Repositories overview","text":"<p>Percona provides two repositories for Percona Distribution for PostgreSQL. </p> Major release repository Minor release repository Major Release repository (<code>ppg-16</code>) it includes the latest version packages. Whenever a package is updated, the package manager of your operating system detects that and prompts you to update. As long as you update all Distribution packages at the same time, you can ensure that the packages you\u2019re using have been tested and verified by Percona.  We recommend installing Percona Distribution for PostgreSQL from the Major Release repository Minor Release repository includes a particular minor release of the database and all of the packages that were tested and verified to work with that minor release (e.g. <code>ppg-16.0</code>). You may choose to install Percona Distribution for PostgreSQL from the Minor Release repository if you have decided to standardize on a particular release which has passed rigorous testing procedures and which has been verified to work with your applications. This allows you to deploy to a new host and ensure that you\u2019ll be using the same version of all the Distribution packages, even if newer releases exist in other repositories.   The disadvantage of using a Minor Release repository is that you are locked in this particular release. When potentially critical fixes are released in a later minor version of the database, you will not be prompted for an upgrade by the package manager of your operating system. You would need to change the configured repository in order to install the upgrade."},{"location":"repo-overview.html#repository-contents","title":"Repository contents","text":"<p>Percona Distribution for PostgreSQL provides individual packages for its components. It also includes two meta-packages: <code>percona-ppg-server</code> and <code>percona-ppg-server-ha</code>.</p> <p>Using a meta-package, you can install all components it contains in one go.</p>"},{"location":"repo-overview.html#percona-ppg-server","title":"<code>percona-ppg-server</code>","text":"Package name on Debian/UbuntuPackage name on RHEL/derivatives <p><code>percona-ppg-server-16</code></p> <p><code>percona-ppg-server16</code></p> <p>The <code>percona-ppg-server</code> meta-package installs the PostgreSQL server with the following packages:</p> Package contents Description <code>percona-postgresql16-server</code> The PostgreSQL server package. <code>percona-postgresql-common</code> PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. <code>percona-postgresql16-contrib</code> A collection of additional PostgreSQLcontrib extensions <code>percona-pg-stat-monitor16</code> A Query Performance Monitoring tool for PostgreSQL. <code>percona-pgaudit16</code> Provides detailed session or object audit logging via the standard PostgreSQL logging facility. <code>percona-pg_repack16</code> rebuilds PostgreSQL database objects. <code>percona-wal2json16</code> a PostgreSQL logical decoding JSON output plugin."},{"location":"repo-overview.html#percona-ppg-server-ha","title":"<code>percona-ppg-server-ha</code>","text":"Package name on Debian/UbuntuPackage name on RHEL/derivatives <p><code>percona-ppg-server-ha-16</code></p> <p><code>percona-ppg-server-16</code></p> <p>The <code>percona-ppg-server-ha</code> meta-package installs high-availability components that are recommended by Percona:</p> Package contents Description <code>percona-patroni</code> A high-availability solution for PostgreSQL. <code>percona-haproxy</code> A high-availability and load-balancing solution <code>etcd</code> A consistent, distributed key-value store <code>python3-python-etcd</code> A Python client for ETCD.<sup>1</sup> <code>etcd-client</code>, <code>etcd-server</code> The client/server of the distributed key-value store. <sup>2</sup> <ol> <li> <p>Is included in repositories for RHEL 8 / CentOS 8 operating systems\u00a0\u21a9</p> </li> <li> <p>Are included in repositories for Debian 12 operating system\u00a0\u21a9</p> </li> </ol>"},{"location":"repo-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"telemetry.html","title":"Telemetry on Percona Distribution for PostgreSQL","text":"<p>Percona telemetry fills in the gaps in our understanding of how you use Percona Distribution for PostgreSQL to improve our products. Participation in this anonymous program is optional. You can opt-out if you prefer to not share this information.</p>"},{"location":"telemetry.html#what-information-is-collected","title":"What information is collected","text":"<p>Currently, telemetry is added only to the Percona packages and Docker images. It collects only information about the installation environment. Future releases may add additional telemetry metrics.</p> <p>Be assured that access to this raw data is rigorously controlled. Percona does not collect personal data. All data is anonymous and cannot be traced to a specific user. To learn more about our privacy practices, read the Percona Privacy statement.</p> <p>The following is an example of the collected data:</p> <pre><code>[{\"id\" : \"c416c3ee-48cd-471c-9733-37c2886f8231\",\n\"product_family\" : \"PRODUCT_FAMILY_PPG\",\n\"instanceId\" : \"6aef422e-56a7-4530-af9d-94cc02198343\",\n\"createTime\" : \"2023-10-16T10:46:23Z\",\n\"metrics\":\n[{\"key\" : \"deployment\",\"value\" : \"PACKAGE\"},\n{\"key\" : \"pillar_version\",\"value\" : \"16.1\"},\n{\"key\" : \"OS\",\"value\" : \"Oracle Linux Server 8.8\"},\n{\"key\" : \"hardware_arch\",\"value\" : \"x86_64 x86_64\"}]}]\n</code></pre>"},{"location":"telemetry.html#disable-telemetry","title":"Disable telemetry","text":"<p>Starting with Percona Distribution for PostgreSQL 16.1, telemetry is enabled by default. If you decide not to send usage data to Percona, you can set the <code>PERCONA_TELEMETRY_DISABLE=1</code> environment variable for either the root user or in the operating system prior to the installation process.</p> Debian-derived distributionRed Hat-derived distributionDOCKER <p>Add the environment variable before the install process.</p> <pre><code>$ sudo PERCONA_TELEMETRY_DISABLE=1 apt install percona-postgresql-16\n</code></pre> <p>Add the environment variable before the install process.</p> <pre><code>$ sudo PERCONA_TELEMETRY_DISABLE=1 yum install percona-postgresql16-server\n</code></pre> <p>Add the environment variable when running a command in a new container.</p> <pre><code>$ docker run --name container-name -e POSTGRES_PASSWORD=secret -e PERCONA_TELEMETRY_DISABLE=1 -d perconalab/percona-distribution-postgresql:tag \n</code></pre>"},{"location":"telemetry.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"third-party.html","title":"Third-party components","text":"<p>Percona Distribution for PostgreSQL is supplied with the set of third-party open source components and tools that provide additional functionality such as high-availability or disaster recovery, without the need of modifying PostgreSQL core code. These components are included in the Percona Distribution for PostgreSQL repository and are tested to work together.</p> Name Superuser privileges Description HAProxy Required A high-availability and load-balancing solution Patroni Required An HA (High Availability) solution for PostgreSQL pgAudit Required Provides detailed session or object audit logging via the standard PostgreSQL logging facility pgAudit set_user Required The <code>set_user</code> part of <code>pgAudit</code> extension provides an additional layer of logging and control when unprivileged users must escalate themselves to superuser or object owner roles in order to perform needed maintenance tasks pgBackRest Required A backup and restore solution for PostgreSQL pgBadger Required A fast PostgreSQL Log Analyzer PgBouncer Required A lightweight connection pooler for PostgreSQL pg_gather Required An SQL script to assess the health of PostgreSQL cluster by gathering performance and configuration data from PostgreSQL databases pgpool2 Required A middleware between PostgreSQL server and client for high availability, connection pooling and load balancing pg_repack Required Rebuilds PostgreSQL database objects pg_stat_monitor Required Collects and aggregates statistics for PostgreSQL and provides histogram information PostGIS Required Allows storing and manipulating spacial data in PostgreSQL wal2json Required A PostgreSQL logical decoding JSON output plugin."},{"location":"third-party.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"trademark-policy.html","title":"Trademark Policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p>"},{"location":"trademark-policy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstalling.html","title":"Uninstalling Percona Distribution for PostgreSQL","text":"<p>To uninstall Percona Distribution for PostgreSQL, remove all the installed packages and data / configuration files.</p> <p>NOTE: Should you need the data files later, back up your data before uninstalling Percona Distribution for PostgreSQL.</p> On Debian and Ubuntu using <code>apt</code>On Red Hat Enterprise Linux and derivatives using <code>yum</code> <p>To uninstall Percona Distribution for PostgreSQL on platforms that use apt package manager such as Debian  or Ubuntu, complete the following steps.</p> <p>Run all commands as root or via sudo.</p> <ol> <li> <p>Stop the Percona Distribution for PostgreSQL service.</p> <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> </li> <li> <p>Remove the percona-postgresql packages.</p> <pre><code>$ sudo apt remove percona-postgresql-16* percona-patroni percona-pgbackrest  percona-pgbadger percona-pgbouncer\n</code></pre> </li> <li> <p>Remove configuration and data files.</p> <pre><code>$ rm -rf /etc/postgresql/16/main\n</code></pre> </li> </ol> <p>To uninstall Percona Distribution for PostgreSQL on platforms that use yum package manager such as  Red Hat Enterprise Linux or CentOS, complete the following steps.</p> <p>Run all commands as root or via sudo.</p> <ol> <li> <p>Stop the Percona Distribution for PostgreSQL service.</p> <pre><code>$ sudo systemctl stop postgresql-16\n</code></pre> </li> <li> <p>Remove the percona-postgresql packages</p> <pre><code>$ sudo yum remove percona-postgresql16* percona-pgbadger\n</code></pre> </li> <li> <p>Remove configuration and data files</p> <pre><code>$ rm -rf /var/lib/pgsql/16/data\n</code></pre> </li> </ol>"},{"location":"uninstalling.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum.html","title":"Install Percona Distribution for PostgreSQL on Red Hat Enterprise Linux and derivatives","text":"<p>This document describes how to install Percona Distribution for PostgreSQL from Percona repositories on RPM-based distributions such as Red Hat Enterprise Linux and compatible derivatives. Read more about Percona repositories .</p>"},{"location":"yum.html#platform-specific-notes","title":"Platform specific notes","text":"<p>Depending on what operating system you are using, you may need to enable or disable specific modules to install Percona Distribution for PostgreSQL packages and to resolve dependencies conflicts for its specific components. </p>"},{"location":"yum.html#for-percona-distribution-for-postgresql-packages","title":"For Percona Distribution for PostgreSQL packages","text":"CentOS 7RHEL8/Oracle Linux 8/Rocky Linux 8 <p>Install the <code>epel-release</code> package:</p> <pre><code>$ sudo yum -y install epel-release\n$ sudo yum repolist\n</code></pre> <p>Disable the <code>postgresql</code>  and <code>llvm-toolset</code>modules:    </p> <pre><code>$ sudo dnf module disable postgresql llvm-toolset\n</code></pre>"},{"location":"yum.html#for-percona-postgresql16-devel-package","title":"For <code>percona-postgresql16-devel</code> package","text":"<p>You may need to install the <code>percona-postgresql16-devel</code> package when working with some extensions or creating programs that interface with PostgreSQL database. This package requires dependencies that are not part of the Distribution, but can be installed from the specific repositories:</p> RHEL8Rocky Linux 8Oracle Linux 8Rocky Linux 9Oracle Linux 9 <pre><code>$ sudo yum --enablerepo=codeready-builder-for-rhel-8-rhui-rpms install perl-IPC-Run -y\n</code></pre> <pre><code>$ sudo dnf install dnf-plugins-core\n$ sudo dnf module enable llvm-toolset\n$ sudo dnf config-manager --set-enabled powertools\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled ol8_codeready_builder install perl-IPC-Run -y\n</code></pre> <pre><code>$ sudo dnf install dnf-plugins-core\n$ sudo dnf module enable llvm-toolset\n$ sudo dnf config-manager --set-enabled crb\n$ sudo dnf install perl-IPC-Run -y\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled ol9_codeready_builder install perl-IPC-Run -y\n</code></pre>"},{"location":"yum.html#for-percona-patroni-package","title":"For <code>percona-patroni</code> package","text":"<p>To install Patroni on Red Hat Enterprise Linux 9 and compatible derivatives, enable the <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre>"},{"location":"yum.html#for-pgpool2-extension","title":"For <code>pgpool2</code> extension","text":"<p>To install <code>pgpool2</code> on Red Hat Enterprise Linux and compatible derivatives, enable the codeready builder repository first to resolve dependencies conflict for <code>pgpool2</code>.</p> <p>The following are commands for Red Hat Enterprise Linux 9 and derivatives. For Red Hat Enterprise Linux 8, replace the operating system version in the commands accordingly. </p> RHEL 9Rocky Linux 9Oracle Linux 9 <pre><code>$ sudo dnf config-manager --set-enabled codeready-builder-for-rhel-9-x86_64-rpms\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled crb\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled ol9_codeready_builder\n</code></pre>"},{"location":"yum.html#for-postgis","title":"For PostGIS","text":"<p>For Red Hat Enterprise Linux 8 and derivatives, replace the operating system version in the following commands accordingly.</p> RHEL 9Rocky Linux 9Oracle Linux 9RHEL UBI 9 <ol> <li> <p>Install <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Enable the <code>llvm-toolset dnf</code> module</p> <pre><code>$ sudo dnf module enable llvm-toolset\n</code></pre> </li> <li> <p>Enable the codeready builder repository to resolve dependencies conflict. </p> <pre><code>$ sudo dnf config-manager --set-enabled codeready-builder-for-rhel-9-x86_64-rpms\n</code></pre> </li> </ol> <ol> <li> <p>Install <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Enable the <code>llvm-toolset dnf</code> module</p> <pre><code>$ sudo dnf module enable llvm-toolset\n</code></pre> </li> <li> <p>Enable the codeready builder repository to resolve dependencies conflict.</p> <pre><code>$ sudo dnf install dnf-plugins-core\n$ sudo dnf config-manager --set-enabled crb\n</code></pre> </li> </ol> <ol> <li> <p>Install <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Enable the <code>llvm-toolset dnf</code> module</p> <pre><code>$ sudo dnf module enable llvm-toolset\n</code></pre> </li> <li> <p>Enable the codeready builder repository to resolve dependencies conflict.</p> <pre><code>$ sudo dnf config-manager --set-enabled ol9_codeready_builder\n</code></pre> </li> </ol> <ol> <li> <p>Configure the Oracle-Linux repository. Create the <code>/etc/yum.repos.d/oracle-linux-ol9.repo</code> file to install the required dependencies: </p> /etc/yum.repos.d/oracle-linux-ol9.repo<pre><code>[ol9_baseos_latest]\nname=Oracle Linux 9 BaseOS Latest ($basearch)\nbaseurl=https://yum.oracle.com/repo/OracleLinux/OL9/baseos/latest/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=1     \n\n[ol9_appstream]\nname=Oracle Linux 9 Application Stream ($basearch)\nbaseurl=https://yum.oracle.com/repo/OracleLinux/OL9/appstream/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=1     \n\n[ol9_codeready_builder]\nname=Oracle Linux 9 CodeReady Builder ($basearch) - Unsupported\nbaseurl=https://yum.oracle.com/repo/OracleLinux/OL9/codeready/builder/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=1\n</code></pre> </li> <li> <p>Download the right GPG key for the Oracle Yum Repository:    </p> <pre><code>$ wget https://yum.oracle.com/RPM-GPG-KEY-oracle-ol9 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n</code></pre> </li> <li> <p>Install <code>epel</code> repository    </p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Disable the upstream <code>postgresql</code> package:    </p> <pre><code>$ sudo dnf module disable postgresql\n</code></pre> </li> </ol>"},{"location":"yum.html#procedure","title":"Procedure","text":"<p>Run all the commands in the following sections as root or using the <code>sudo</code> command:</p>"},{"location":"yum.html#install-dependencies","title":"Install dependencies","text":"<p>Install <code>curl</code> for Telemetry. We use it to better understand the use of our products and improve them.</p> <pre><code>$ sudo yum -y install curl\n</code></pre>"},{"location":"yum.html#configure-the-repository","title":"Configure the repository","text":"<ol> <li> <p>Install the <code>percona-release</code> repository management tool to subscribe to Percona repositories:</p> <pre><code>$ sudo yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the repository</p> </li> </ol> <p>Percona provides two repositories for Percona Distribution for PostgreSQL. We recommend enabling the Major release repository to timely receive the latest updates. </p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre>"},{"location":"yum.html#install-packages","title":"Install packages","text":"Install using meta-packageInstall packages individually <p>The meta package enables you to install several components of the distribution in one go.</p> <pre><code>$ sudo yum install percona-ppg-server16\n</code></pre> <ol> <li> <p>Install the PostgreSQL server package:</p> <pre><code>$ sudo yum install percona-postgresql16-server\n</code></pre> </li> <li> <p>Install the components:</p> <p>Install <code>pg_repack</code>:</p> <pre><code>$ sudo yum install percona-pg_repack16\n</code></pre> <p>Install <code>pgaudit</code>:</p> <pre><code>$ sudo yum install percona-pgaudit16\n</code></pre> <p>Install <code>pgBackRest</code>:</p> <pre><code>$ sudo yum install percona-pgbackrest\n</code></pre> <p>Install <code>Patroni</code>:</p> <pre><code>$ sudo yum install percona-patroni\n</code></pre> <p>Install <code>pg_stat_monitor</code>:</p> <p>Install <code>pgBouncer</code>:</p> <pre><code>$ sudo yum install percona-pgbouncer\n</code></pre> <p>Install <code>pgAudit-set_user</code>:</p> <pre><code>$ sudo yum install percona-pgaudit16_set_user\n</code></pre> <p>Install <code>pgBadger</code>:</p> <pre><code>$ sudo yum install percona-pgbadger\n</code></pre> <p>Install <code>wal2json</code>:</p> <pre><code>$ sudo yum install percona-wal2json16\n</code></pre> <p>Install PostgreSQL contrib extensions:</p> <pre><code>$ sudo yum install percona-postgresql16-contrib\n</code></pre> <p>Install HAProxy</p> <pre><code>$ sudo yum install percona-haproxy\n</code></pre> <p>Install <code>pg_gather</code></p> <pre><code>$ sudo yum install percona-pg_gather\n</code></pre> <p>Install pgpool2</p> <ol> <li>Check the platform specific notes</li> <li> <p>Install the extension</p> <pre><code>$ sudo yum install percona-pgpool-II-pg16\n</code></pre> </li> </ol> <p>Some extensions require additional setup in order to use them with Percona Distribution for PostgreSQL. For more information, refer to Enabling extensions.</p> </li> </ol>"},{"location":"yum.html#start-the-service","title":"Start the service","text":"<p>After the installation, the default database storage is not automatically initialized. To complete the installation and start Percona Distribution for PostgreSQL, initialize the database using the following command:</p> <pre><code>$ /usr/pgsql-16/bin/postgresql-16-setup initdb\n</code></pre> <p>Start the PostgreSQL service:</p> <pre><code>$ sudo systemctl start postgresql-16\n</code></pre>"},{"location":"yum.html#connect-to-the-postgresql-server","title":"Connect to the PostgreSQL server","text":"<p>By default, <code>postgres</code> user and <code>postgres</code> database are created in PostgreSQL upon its installation and initialization. This allows you to connect to the database as the <code>postgres</code> user.</p> <pre><code>$ sudo su postgres\n</code></pre> <p>Open the PostgreSQL interactive terminal:</p> <pre><code>$ psql\n</code></pre> <p>Hint</p> <p>You can connect to <code>psql</code> as the <code>postgres</code> user in one go:</p> <pre><code>$ sudo su - postgres -c psql\n</code></pre> <p>To exit the <code>psql</code> terminal, use the following command:</p> <pre><code>$ \\q\n</code></pre>"},{"location":"yum.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/backup-recovery.html","title":"Backup and disaster recovery in Percona Distribution for PostgreSQL","text":"<p>Summary</p> <ul> <li>Overview</li> <li>Architecture</li> <li>Deployment </li> <li>Testing</li> </ul>"},{"location":"solutions/backup-recovery.html#overview","title":"Overview","text":"<p>A Disaster Recovery (DR) solution ensures that a system can be quickly restored to a normal operational state if something unexpected happens. When operating a database, you would back up the data as frequently as possible and have a mechanism to restore that data when needed. Disaster Recovery is often mistaken for high availability (HA), but they are two different concepts altogether:</p> <ul> <li>High availability ensures guaranteed service levels at all times. This solution involves configuring one or more standby systems to an active database, and the ability to switch seamlessly to that standby when the primary database becomes unavailable, for example, during a power outage or a server crash. To learn more about high-availability solutions with Percona Distribution for PostgreSQL, refer to High Availability in PostgreSQL with Patroni.</li> <li>Disaster Recovery protects the database instance against accidental or malicious data loss or data corruption. Disaster recovery can be achieved by using either the options provided by PostgreSQL, or external extensions.</li> </ul> <p></p> PostgreSQL disaster recovery options <p> PostgreSQL offers multiple options for setting up database disaster recovery. </p> <ul> <li>pg_dump or the pg_dumpall utilities</li> </ul> <p>This is the basic backup approach. These tools can generate the backup of one or more PostgreSQL databases (either just the structure, or both the structure and data), then restore them through the pg_restore command. </p> Advantages Disadvantages Easy to use 1. Backup of only one database at a time.2. No incremental backups.3. No point-in-time recovery since the backup is a snapshot in time.4. Performance degradation when the database size is large. <ul> <li>File-based backup and restore</li> </ul> <p>This method involves backing up the PostgreSQL data directory to a different location, and restoring it when needed. </p> Advantages Disadvantages Consistent snapshot of the data directory or the whole data disk volume 1. Requires stopping PostgreSQL in order to copy the files. This is not practical for most production setups. 2. No backup of individual databases or tables. <ul> <li>PostgreSQL pg_basebackup</li> </ul> <p>This backup tool is provided by PostgreSQL. It is used to back up data when the database instance is running. <code>pgasebackup</code> makes a binary copy of the database cluster files, while making sure the system is put in and out of backup mode automatically. </p> Advantages Disadvantages 1. Supports backups when the database is running.2. Supports point-in-time recovery 1. No incremental backups.2. No backup of individual databases or tables. <p></p> <p>To achieve a production grade PostgreSQL disaster recovery solution, you need something that can take full or incremental database backups from a running instance, and restore from those backups at any point in time. Percona Distribution for PostgreSQL is supplied with pgBackRest: a reliable, open-source backup and recovery solution for PostgreSQL.</p> <p>This document focuses on the Disaster recovery solution in Percona Distribution for PostgreSQL. The Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL tutorial provides guidelines of how to set up and test this solution.</p>"},{"location":"solutions/backup-recovery.html#pgbackrest","title":"pgBackRest","text":"<p>pgBackRest is an easy-to-use, open-source solution that can reliably back up even the largest of PostgreSQL databases. <code>pgBackRest</code> supports the following backup types:</p> <ul> <li>full backup - a complete copy of your entire data set.</li> <li>differential backup - includes all data that has changed since the last full backup. While this means the backup time is slightly higher, it enables a faster restore.</li> <li>incremental backup - only backs up the files that have changed since the last full or differential backup, resulting in a quick backup time. To restore to a point in time, however, you will need to restore each incremental backup in the order they were taken.</li> </ul> <p>When it comes to restoring, <code>pgBackRest</code> can do a full or a delta restore. A full restore needs an empty PostgreSQL target directory. A delta restore is intelligent enough to recognize already-existing files in the PostgreSQL data directory, and update only the ones the backup contains. </p> <p><code>pgBackRest</code> supports remote repository hosting and can even use cloud-based services like AWS S3, Google Cloud Services Cloud Storage, Azure Blob Storage for saving backup files. It supports parallel backup through multi-core processing and compression. By default, backup integrity is verified through checksums, and saved files can be encrypted for enhanced security.</p> <p><code>pgBackRest</code> can restore a database to a specific point in time in the past. This is the case where a database is not inaccessible but perhaps contains corrupted data. Using the point-in-time recovery, a database administrator can restore the database to the last known good state.  </p> <p>Finally, <code>pgBackRest</code> also supports restoring PostgreSQL databases to a different PostgreSQL instance or a separate data directory.</p>"},{"location":"solutions/backup-recovery.html#setup-overview","title":"Setup overview","text":"<p>This section describes the architecture of the backup and disaster recovery solution. For the configuration steps, refer to the Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL.</p>"},{"location":"solutions/backup-recovery.html#system-architecture","title":"System architecture","text":"<p>As the configuration example, we will use a three server architecture where <code>pgBackRest</code> resides on a dedicated remote host. The servers communicate with each other via passwordless SSH.</p> <p>Important</p> <p>Passwordless SSH may not be an ideal solution for your environment. In this case, consider using other methods, for example, TLS with client certificates.</p> <p>The following diagram illustrates the architecture layout:</p> <p></p>"},{"location":"solutions/backup-recovery.html#components","title":"Components:","text":"<p>The architecture consists of three server instances:</p> <ul> <li><code>pg-primary</code> hosts the primary PostgreSQL server. Note that \u201cprimary\u201d here means the main database instance and does not refer to the primary node of a PostgreSQL replication cluster or a HA setup.</li> <li><code>pg-repo</code> is the remote backup repository and hosts <code>pgBackRest</code>. It\u2019s important to host the backup repository on a physically separate instance, to be accessed when the target goes down. </li> <li><code>pg-secondary</code> is the secondary PostgreSQL node. Don\u2019t confuse it with a hot standby. \u201cSecondary\u201d in this context means a PostgreSQL instance that\u2019s idle. We will restore the database backup to this instance when the primary PostgreSQL instance goes down. </li> </ul> <p>Note</p> <p>For simplicity, we use a single-node PostgreSQL instance as the primary database server. In a production scenario, you will use some form of high-availability solution to protect the primary instance. When you are using a high-availability setup, we recommend configuring <code>pgBackRest</code> to back up the hot standby server so the primary node is not unnecessarily loaded.</p>"},{"location":"solutions/backup-recovery.html#deployment","title":"Deployment","text":"<p>Refer to the Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL tutorial.  </p>"},{"location":"solutions/backup-recovery.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/dr-pgbackrest-setup.html","title":"Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL","text":"<p>This document provides instructions of how to set up and test the backup and disaster recovery solution in Percona Distribution for PostgreSQL with <code>pgBackRest</code>. For technical overview and architecture description of this solution, refer to Backup and disaster recovery in Percona Distribution for PostgreSQL.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#deployment","title":"Deployment","text":"<p>As the example configuration, we will use the nodes with the following IP addresses:</p> Node name Internal IP address pg-primary 10.104.0.3 pg-repo 10.104.0.5 pg-secondary 10.104.0.4"},{"location":"solutions/dr-pgbackrest-setup.html#set-up-hostnames","title":"Set up hostnames","text":"<p>In our architecture, the <code>pgBackRest</code> repository is located on a remote host. To allow communication among the nodes, passwordless SSH is required. To achieve this, properly setting up hostnames in the <code>/etc/hosts</code> files is very important.</p> <ol> <li> <p>Define the hostname for every server in the <code>/etc/hostname</code> file. The following are the examples of how the <code>/etc/hostname</code> file in three nodes looks like:</p> <pre><code>cat /etc/hostname\npg-primary\n</code></pre> <pre><code>cat /etc/hostname\npg-repo\n</code></pre> <pre><code>cat /etc/hostname\npg-secondary\n</code></pre> </li> <li> <p>For the nodes to communicate seamlessly across the network, resolve their hostnames to their IP addresses in the <code>/etc/hosts</code> file.  (Alternatively, you can make appropriate entries in your internal DNS servers)</p> </li> </ol> <p>The <code>/etc/hosts</code> file  for the <code>pg-primary node</code> looks like this:</p> <pre><code>```\n127.0.1.1 pg-primary pg-primary\n127.0.0.1 localhost\n10.104.0.5 pg-repo\n```\n</code></pre> <p>The <code>/etc/hosts</code> file in the <code>pg-repo</code> node looks like this:</p> <pre><code>```\n127.0.1.1 pg-repo pg-repo\n127.0.0.1 localhost\n10.104.0.3 pg-primary\n10.104.0.4 pg-secondary\n```\n</code></pre> <p>The <code>/etc/hosts</code> file in the <code>pg-secondary</code> node is shown below:</p> <pre><code>```\n127.0.1.1 pg-secondary pg-secondary\n127.0.0.1 localhost\n10.104.0.3 pg-primary\n10.104.0.5 pg-repo\n```\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#set-up-passwordless-ssh","title":"Set up passwordless SSH","text":"<p>Before setting up passwordless SSH, ensure that the postgres user in all three instances has a password. </p> <ol> <li> <p>To set or change the password, run the following command as a root user:</p> <pre><code>$ passwd postgres\n</code></pre> </li> <li> <p>Type the new password and confirm it. </p> </li> <li> <p>After setting up the password, edit the <code>/etc/ssh/sshd_config</code> file and ensure the <code>PasswordAuthentication</code> variable is set as <code>yes</code>. </p> <pre><code>PasswordAuthentication yes \n</code></pre> </li> <li> <p>In the <code>pg-repo</code> node, restart the <code>sshd</code> service. Without the restart, the SSH server will not allow you to connect to it using a password while adding the keys.</p> <pre><code>$ sudo service sshd restart\n</code></pre> </li> <li> <p>In the <code>pg-primary</code> node, generate an SSH key pair and add the public key to the <code>pg-repo</code> node. </p> <p>Important</p> <p>Run the commands as the postgres user. </p> <ul> <li> <p>Generate SSH keys:   </p> <pre><code>$ ssh-keygen -t rsa\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa\nYour public key has been saved in /root/.ssh/id_rsa.pub\nThe key fingerprint is:\n...\n</code></pre> </li> <li> <p>Copy the public key to the <code>pg-repo</code> node:</p> <pre><code>$ ssh-copy-id -i ~/.ssh/id_rsa.pub postgres@pg-repo\n/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\"\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\npostgres@pg-repo's password: \n\nNumber of key(s) added: 1\n\n\nNow try logging into the machine, with:   \"ssh 'postgres@pg-repo'\"\nand check to make sure that only the key(s) you wanted were added.\n</code></pre> </li> </ul> </li> <li> <p>To verify everything has worked as expected, run the following command from the <code>pg-primary</code> node. </p> <pre><code>$ ssh postgres@pg-repo\n</code></pre> <p>You should be able to connect to the <code>pg-repo</code> terminal without a password.</p> </li> <li> <p>Repeat the SSH connection from <code>pg-repo</code> to <code>pg-primary</code> to ensure that passwordless SSH is working. </p> </li> <li>Set up bidirectional passwordless SSH between <code>pg-repo</code> and <code>pg-secondary</code> using the same method. This will allow <code>pg-repo</code> to recover the backups to <code>pg-secondary</code>. </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#install-percona-distribution-for-postgresql","title":"Install Percona Distribution for PostgreSQL","text":"<p>Install Percona Distribution for PostgreSQL in the primary and the secondary nodes from Percona repository. </p> <ol> <li>Install <code>percona-release</code>.</li> <li> <p>Enable the repository:</p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages</p> On Debian and UbuntuOn RedHat Enterprise Linux and derivatives <pre><code>$ sudo apt install percona-postgresql-16 -y\n</code></pre> <pre><code>$ sudo yum install percona-postgresql16-server\n</code></pre> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#configure-postgresql-on-the-primary-node-for-continuous-backup","title":"Configure PostgreSQL on the primary node for continuous backup","text":"<p>At this step, configure the PostgreSQL instance on the <code>pg-primary</code> node for continuous archiving of the WAL files. </p> <p>Note</p> <p>On Debian and Ubuntu, the path to the configuration file is <code>/etc/postgresql/16/main/postgresql.conf</code>.</p> <p>On RHEL and CentOS, the path to the configuration file is <code>/var/lib/pgsql/16/data/</code>.</p> <ol> <li> <p>Edit the <code>postgresql.conf</code> configuration file to include the following changes:</p> <pre><code>archive_command = 'pgbackrest --stanza=prod_backup archive-push %p'\narchive_mode = on\nlisten_addresses = '*'\nlog_line_prefix = ''\nmax_wal_senders = 3\nwal_level = replica\n</code></pre> </li> <li> <p>Once the changes are saved, restart PostgreSQL.</p> <pre><code>$ sudo systemctl restart postgresql\n</code></pre> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#install-pgbackrest","title":"Install pgBackRest","text":"<p>Install <code>pgBackRest</code> in all three instances from Percona repository. Use the following command:</p> On Debian / UbuntuOn RHEL / derivatives <pre><code>$ sudo apt-get install percona-pgbackrest\n</code></pre> <pre><code>$ sudo yum install percona-pgbackrest\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#create-the-pgbackrest-configuration-file","title":"Create the <code>pgBackRest</code> configuration file","text":"<p>Run the following commands on all three nodes to set up the required configuration file for <code>pgBackRest</code>.</p> <ol> <li> <p>Configure a location and permissions for the <code>pgBackRest</code> log rotation:</p> <pre><code>$ sudo mkdir -p -m 770 /var/log/pgbackrest\n$ sudo chown postgres:postgres /var/log/pgbackrest\n</code></pre> </li> <li> <p>Configure the location and permissions for the <code>pgBackRest</code> configuration file:</p> </li> </ol> <pre><code>$ sudo mkdir -p /etc/pgbackrest\n$ sudo mkdir -p /etc/pgbackrest/conf.d\n$ sudo touch /etc/pgbackrest/pgbackrest.conf\n$ sudo chmod 640 /etc/pgbackrest/pgbackrest.conf\n$ sudo chown postgres:postgres /etc/pgbackrest/pgbackrest.conf\n$ sudo mkdir -p /home/pgbackrest\n$ sudo chmod postgres:postgres /home/pgbackrest\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#update-pgbackrest-configuration-file-in-the-primary-node","title":"Update <code>pgBackRest</code> configuration file in the primary node","text":"<p>Configure <code>pgBackRest</code> on the <code>pg-primary</code> node by setting up a stanza. A stanza is a set of configuration parameters that tells <code>pgBackRest</code> where to backup its files. Edit the <code>/etc/pgbackrest/pgbackrest.conf</code> file in the <code>pg-primary</code> node to include the following lines:</p> <pre><code>[global]\nrepo1-host=pg-repo \nrepo1-host-user=postgres\nprocess-max=2\nlog-level-console=info\nlog-level-file=debug\n\n[prod_backup]\npg1-path=/var/lib/postgresql/14/main\n</code></pre> <p>You can see the <code>pg1-path</code> attribute for the <code>prod_backup</code> stanza has been set to the PostgreSQL data folder.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#update-pgbackrest-configuration-file-in-the-remote-backup-repository-node","title":"Update <code>pgBackRest</code> configuration file in the remote backup repository node","text":"<p>Add a stanza for the <code>pgBackRest</code> in the <code>pg-repo</code> node. Edit the <code>/etc/pgbackrest/pgbackrest.conf</code> configuration file to include the following lines:</p> <pre><code>[global]\nrepo1-path=/home/pgbackrest/pg_backup\nrepo1-retention-full=2\nprocess-max=2\nlog-level-console=info\nlog-level-file=debug\nstart-fast=y\nstop-auto=y\n\n[prod_backup]\npg1-path=/var/lib/postgresql/14/main\npg1-host=pg-primary\npg1-host-user=postgres\npg1-port = 5432\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#initialize-pgbackrest-stanza-in-the-remote-backup-repository-node","title":"Initialize <code>pgBackRest</code> stanza in the remote backup repository node","text":"<p>After the configuration files are set up, it\u2019s now time to initialize the <code>pgBackRest</code> stanza. Run the following command in the remote backup repository node (<code>pg-repo</code>).</p> <pre><code>$ sudo -u postgres pgbackrest --stanza=prod_backup stanza-create\n2021-11-07 11:08:18.157 P00   INFO: stanza-create command begin 2.36: --exec-id=155883-2277a3e7 --log-level-console=info --log-level-file=off --pg1-host=pg-primary --pg1-host-user=postgres --pg1-path=/var/lib/postgresql/14/main --pg1-port=5432 --repo1-path=/home/pgbackrest/pg_backup --stanza=prod_backup\n2021-11-07 11:08:19.453 P00   INFO: stanza-create for stanza 'prod_backup' on repo1\n2021-11-07 11:08:19.566 P00   INFO: stanza-create command end: completed successfully (1412ms)\n</code></pre> <p>Once the stanza is created successfully, you can try out the different use cases for disaster recovery.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#testing-backup-and-restore-with-pgbackrest","title":"Testing Backup and Restore with <code>pgBackRest</code>","text":"<p>This section covers a few use cases where <code>pgBackRest</code> can back up and restore databases either in the same instance or a different node.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-1-create-a-backup-with-pgbackrest","title":"Use Case 1: Create a backup with <code>pgBackRest</code>","text":"<ol> <li> <p>To start our testing, let\u2019s create a table in the <code>postgres</code> database in the <code>pg-primary</code> node and add some data.</p> <pre><code>CREATE TABLE CUSTOMER (id integer, name text);\nINSERT INTO CUSTOMER VALUES (1,'john');\nINSERT INTO CUSTOMER VALUES (2,'martha');\nINSERT INTO CUSTOMER VALUES (3,'mary');\n</code></pre> </li> <li> <p>Take a full backup of the database instance. Run the following commands from the <code>pg-repo</code> node:</p> </li> </ol> <pre><code>$ pgbackrest -u postgres  --stanza=prod_backup backup --type=full\n</code></pre> <p>If you want an incremental backup, you can omit the <code>type</code> attribute. By default, <code>pgBackRest</code> always takes an incremental backup except the first backup of the cluster which is always a full backup. </p> <p>If you need a differential backup,  use diff for the <code>type</code> field:</p> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup backup --type=diff\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-2-restore-a-postgresql-instance-from-a-full-backup","title":"Use Case 2: Restore a PostgreSQL Instance from a full backup","text":"<p>For testing purposes, let\u2019s \u201cdamage\u201d the PostgreSQL instance. </p> <ol> <li> <p>Run the following command in the <code>pg-primary</code> node to delete the main data directory.</p> <pre><code>$ rm -rf /var/lib/postgresql/14/main/*\n</code></pre> </li> <li> <p>To restore the backup, run the following commands. </p> <ul> <li>Stop the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl stop postgresql\n</code></pre> <ul> <li>Restore the backup:</li> </ul> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup restore\n</code></pre> <ul> <li>Start the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl start postgresql\n</code></pre> </li> <li> <p>After the command executes successfully, you can access PostgreSQL from the <code>psql</code> command line tool and check if the table and data rows have been restored.</p> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-3-point-in-time-recovery","title":"Use Case 3: Point-In-Time Recovery","text":"<p>If your target PostgreSQL instance has an already existing data directory, the full restore option will fail. You will get an error message stating there are existing data files.  In this case, you can use the <code>--delta</code> option to restore only the corrupted files. </p> <p>For example, let\u2019s say one of your developers mistakenly deleted a few rows from a table. You can use <code>pgBackRest</code> to revert your database to a previous point in time to recover the lost rows.</p> <p>To test this use case, do the following:</p> <ol> <li> <p>Take a timestamp when the database is stable and error-free. Run the following command from the <code>psql</code>prompt.</p> <pre><code>SELECT CURRENT_TIMESTAMP;\n       current_timestamp       \n-------------------------------\n 2021-11-07 11:55:47.952405+00\n(1 row)\n</code></pre> <p>Note down the above timestamp since we will use this time in the restore command. Note that in a real life scenario, finding the correct point in time when the database was error-free may require extensive investigation. It is also important to note that all changes after the selected point will be lost after the roll back. </p> </li> <li> <p>Delete one of the customer records added before.</p> <pre><code>DELETE FROM CUSTOMER WHERE ID=3;\n</code></pre> </li> <li> <p>To recover the data, run a command with the noted timestamp as an argument. Run the commands below to recover the database up to that time.</p> <ul> <li>Stop the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl stop postgresql\n</code></pre> <ul> <li>Restore the backup</li> </ul> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup --delta \\\n--type=time \"--target= 2021-11-07 11:55:47.952405+00\" \\\n--target-action=promote restore\n</code></pre> <ul> <li>Start the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl start postgresql\n</code></pre> </li> <li> <p>Check the database table to see if the record has been restored.</p> <pre><code>SELECT * FROM customer;\n id |  name  \n----+--------\n  1 | john\n  2 | martha\n  3 | mary\n(3 rows)\n</code></pre> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-4-restoring-to-a-separate-postgresql-instance","title":"Use Case 4: Restoring to a Separate PostgreSQL Instance","text":"<p>Sometimes a PostgreSQL server may encounter hardware issues and become completely inaccessible. In such cases, we will need to recover the database to a separate instance where <code>pgBackRest</code> is not initially configured. To restore the instance to a separate host, you have to first install both PostgreSQL and <code>pgBackRest</code> in this host. </p> <p>In our test setup, we already have PostgreSQL and <code>pgBackRest</code> installed in the third node, <code>pg-secondary</code>. Change the <code>pgBackRest</code> configuration file in the <code>pg-secondary</code> node as shown below.</p> <pre><code>[global]\nrepo1-host=pg-repo\nrepo1-host-user=postgres\nprocess-max=2\nlog-level-console=info\nlog-level-file=debug\n\n[prod_backup]\npg1-path=/var/lib/postgresql/14/main\n</code></pre> <p>There should be bidirectional passwordless SSH communication between <code>pg-repo</code> and <code>pg-secondary</code>. Refer to the Set up passwordless SSH section for the steps, if you haven\u2019t configured it. </p> <p>Stop the PostgreSQL instance</p> <pre><code>$ sudo systemctl stop postgresql\n</code></pre> <p>Restore the database backup from <code>pg-repo</code> to <code>pg-secondary</code>.</p> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup --delta restore\n\n2021-11-07 13:34:08.897 P00   INFO: restore command begin 2.36: --delta --exec-id=109728-d81c7b0b --log-level-console=info --log-level-file=debug --pg1-path=/var/lib/postgresql/14/main --process-max=2 --repo1-host=pg-repo --repo1-host-user=postgres --stanza=prod_backup\n2021-11-07 13:34:09.784 P00   INFO: repo1: restore backup set 20211107-111534F_20211107-131807I, recovery will start at 2021-11-07 13:18:07\n2021-11-07 13:34:09.786 P00   INFO: remove invalid files/links/paths from '/var/lib/postgresql/14/main'\n2021-11-07 13:34:11.803 P00   INFO: write updated /var/lib/postgresql/14/main/postgresql.auto.conf\n2021-11-07 13:34:11.819 P00   INFO: restore global/pg_control (performed last to ensure aborted restores cannot be started)\n2021-11-07 13:34:11.819 P00   INFO: restore size = 23.2MB, file total = 937\n2021-11-07 13:34:11.820 P00   INFO: restore command end: completed successfully (2924ms)\n</code></pre> <p>After the restore completes successfully, restart PostgreSQL:</p> <pre><code>$ sudo systemctl start postgresql\n</code></pre> <p>Check the database contents from the local <code>psql</code> shell. </p> <pre><code>SELECT * FROM customer;\n id |  name  \n----+--------\n  1 | john\n  2 | martha\n  3 | mary\n(3 rows)\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/ha-setup-apt.html","title":"Deploying PostgreSQL for high availability with Patroni on Debian or Ubuntu","text":"<p>This guide provides instructions on how to set up a highly available PostgreSQL cluster with Patroni on Debian or Ubuntu. </p>"},{"location":"solutions/ha-setup-apt.html#preconditions","title":"Preconditions","text":"<ol> <li>This is the example deployment suitable to be used for testing purposes in non-production environments. </li> <li>In this setup ETCD resides on the same hosts as Patroni. In production, consider deploying ETCD cluster on dedicated hosts or at least have separate disks for ETCD and PostgreSQL. This is because ETCD writes every request from the cluster to disk which can be CPU intensive and affects disk performance. See hardware recommendations for details.</li> <li>For this setup, we will use the nodes running on Ubuntu 22.04 as the base operating system:</li> </ol> Node name Public IP address Internal IP address node1 157.230.42.174 10.104.0.7 node2 68.183.177.183 10.104.0.2 node3 165.22.62.167 10.104.0.8 HAProxy-demo 134.209.111.138 10.104.0.6 <p>Note</p> <p>In a production (or even non-production) setup, the PostgreSQL nodes will be within a private subnet without any public connectivity to the Internet, and the HAProxy will be in a different subnet that allows client traffic coming only from a selected IP range. To keep things simple, we have implemented this architecture in a DigitalOcean VPS environment, and each node can access the other by its internal, private IP. </p>"},{"location":"solutions/ha-setup-apt.html#initial-setup","title":"Initial setup","text":"<p>It\u2019s not necessary to have name resolution, but it makes the whole setup more readable and less error prone. Here, instead of configuring a DNS, we use a local name resolution by updating the file <code>/etc/hosts</code>. By resolving their hostnames to their IP addresses, we make the nodes aware of each other\u2019s names and allow their seamless communication.</p> <ol> <li> <p>Run the following command on each node. Change the node name to <code>node1</code>, <code>node2</code> and <code>node3</code> respectively:</p> <pre><code>$ sudo hostnamectl set-hostname node-1\n</code></pre> </li> <li> <p>Modify the <code>/etc/hosts</code> file of each PostgreSQL node to include the hostnames and IP addresses of the remaining nodes. Add the following at the end of the <code>/etc/hosts</code> file on all nodes:</p> node1node2node3HAproxy-demo <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <p>The HAProxy instance should have the name resolution for all the three nodes in its <code>/etc/hosts</code> file. Add the following lines at the end of the file:    </p> <pre><code># Cluster IP and names\n10.104.0.6 HAProxy-demo\n10.104.0.1 node1\n10.104.0.2 node2\n10.104.0.3 node3\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#install-the-software","title":"Install the software","text":"<p>Run the following commands on node1<code>,</code>node2<code>and</code>node3`:</p> <ol> <li> <p>Install Percona Distribution for PostgreSQL</p> <ul> <li> <p>Install <code>percona-release</code>.</p> </li> <li> <p>Enable the repository:</p> </li> </ul> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> <ul> <li>Install Percona Distribution for PostgreSQL packages.</li> </ul> </li> <li> <p>Install some Python and auxiliary packages to help with Patroni and ETCD</p> <pre><code>$ sudo apt install python3-pip python3-dev binutils\n</code></pre> </li> <li> <p>Install ETCD, Patroni, pgBackRest packages:</p> <pre><code>$ sudo apt install percona-patroni \\\netcd etcd-server etcd-client \\\npercona-pgbackrest\n</code></pre> </li> <li> <p>Stop and disable all installed services:</p> <pre><code>$ sudo systemctl stop {etcd,patroni,postgresql}\n$ systemctl disable {etcd,patroni,postgresql}\n</code></pre> </li> <li> <p>Even though Patroni can use an existing Postgres installation, remove the data directory to force it to initialize a new Postgres cluster instance.</p> </li> </ol> <pre><code>$ sudo systemctl stop postgresql\n$ sudo rm -rf /var/lib/postgresql/16/main\n</code></pre>"},{"location":"solutions/ha-setup-apt.html#configure-etcd-distributed-store","title":"Configure ETCD distributed store","text":"<p>The distributed configuration store helps establish a consensus among nodes during a failover and will manage the configuration for the three PostgreSQL instances. Although Patroni can work with other distributed consensus stores (i.e., Zookeeper, Consul, etc.), the most commonly used one is <code>etcd</code>. </p> <p>The <code>etcd</code> cluster is first started in one node and then the subsequent nodes are added to the first node using the <code>add</code>command. The configuration is stored in the <code>/etc/default/etcd</code> file.</p>"},{"location":"solutions/ha-setup-apt.html#configure-node1","title":"Configure <code>node1</code>","text":"<ol> <li> <p>Back up the configuration file</p> <pre><code>$ sudo mv /etc/default/etcd /etc/default/etcd.orig\n</code></pre> </li> <li> <p>Export environment variables to simplify the config file creation</p> <ul> <li>Node name:</li> </ul> <pre><code>$ export NODE_NAME=`hostname -f`\n</code></pre> <ul> <li>Node IP:</li> </ul> <pre><code>$ export NODE_IP=`hostname -i | awk '{print $1}'`\n</code></pre> <ul> <li>Initial cluster token for the ETCD cluster during bootstrap:</li> </ul> <pre><code>$ export ETCD_TOKEN='PostgreSQL_HA_Cluster_1'\n</code></pre> <ul> <li>ETCD data directory:</li> </ul> <pre><code>$ export ETCD_DATA_DIR='/var/lib/etcd/postgresql'\n</code></pre> </li> <li> <p>Modify the <code>/etc/default/etcd</code> configuration file as follows:. </p> <pre><code>$ echo \"\nETCD_NAME=${NODE_NAME}\nETCD_INITIAL_CLUSTER=\"${NODE_NAME}=http://${NODE_IP}:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\nETCD_INITIAL_CLUSTER_TOKEN=\"${ETCD_TOKEN}\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_DATA_DIR=\"${ETCD_DATA_DIR}\"\nETCD_LISTEN_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://${NODE_IP}:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://${NODE_IP}:2379\"\n\" | sudo tee -a /etc/default/etcd\n</code></pre> </li> <li> <p>Start the <code>etcd</code> service to apply the changes on <code>node1</code>.</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member list\n</code></pre> <p>Sample output:</p> <pre><code>21d50d7f768f153a: name=default peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379 isLeader=true\n</code></pre> </li> <li> <p>Add the <code>node2</code> to the cluster. Run the following command on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member add node2 http://10.104.0.2:2380\n</code></pre> <p>The output resembles the following one:</p> <pre><code>Added member named node2 with ID 10042578c504d052 to cluster\n\nETCD_NAME=\"node2\"\nETCD_INITIAL_CLUSTER=\"node2=http://10.104.0.2:2380,node1=http://10.104.0.1:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\n</code></pre> </li> <li> <p>Back up the configuration file and export environment variables as described in steps 1-2 of the <code>node1</code> configuration </p> </li> <li> <p>Edit the <code>/etc/default/etcd</code> configuration file on <code>node2</code>. Use the result of the <code>add</code> command on <code>node1</code> to change the configuration file as follows:</p> <pre><code>$ echo \"\nETCD_NAME=\"node2\"\nETCD_INITIAL_CLUSTER=\"node1=http://10.0.100.1:2380,node2=http://10.0.100.2:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\n\nETCD_INITIAL_CLUSTER_TOKEN=\"${ETCD_TOKEN}\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_DATA_DIR=\"${ETCD_DATA_DIR}\"\nETCD_LISTEN_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://${NODE_IP}:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://${NODE_IP}:2379\"\n\" | sudo tee -a /etc/default/etcd\n</code></pre> </li> <li> <p>Start the <code>etcd</code> service to apply the changes on <code>node2</code>:</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#configure-node2","title":"Configure <code>node2</code>","text":""},{"location":"solutions/ha-setup-apt.html#configure-node3","title":"Configure <code>node3</code>","text":"<ol> <li> <p>Add <code>node3</code> to the cluster. Run the following command on <code>node1</code></p> <pre><code>$ sudo etcdctl member add node3 http://10.104.0.3:2380\n</code></pre> </li> <li> <p>On <code>node3</code>, back up the configuration file and export environment variables as described in steps 1-2 of the <code>node1</code> configuration </p> </li> <li> <p>Modify the <code>/etc/default/etcd</code> configuration file and add the output of the <code>add</code> command:</p> <pre><code>$ echo \"\nETCD_NAME=node3\nETCD_INITIAL_CLUSTER=\"node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380,node3=http://10.104.0.3:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"  \nETCD_INITIAL_CLUSTER_TOKEN=\"${ETCD_TOKEN}\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_DATA_DIR=\"${ETCD_DATA_DIR}\"\nETCD_LISTEN_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://${NODE_IP}:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://${NODE_IP}:2379\"\n\" | sudo tee -a /etc/default/etcd\n</code></pre> </li> <li> <p>Start the <code>etcd</code> service on <code>node3</code>:</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members.</p> <pre><code>$ sudo etcdctl member list\n</code></pre> <p>The output resembles the following:</p> <pre><code>2d346bd3ae7f07c4: name=node2 peerURLs=http://10.104.0.2:2380 clientURLs=http://10.104.0.2:2379 isLeader=false\n8bacb519ebdee8db: name=node3 peerURLs=http://10.104.0.3:2380 clientURLs=http://10.104.0.3:2379 isLeader=false\nc5f52ea2ade25e1b: name=node1 peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379 isLeader=true\n</code></pre> </li> </ol> <p>Run the following commands on all nodes. You can do this in parallel:</p> <ol> <li> <p>Export and create environment variables to simplify the config file creation:</p> <ul> <li>Node name:</li> </ul> <pre><code>$ export NODE_NAME=`hostname -f`\n</code></pre> <ul> <li>Node IP:</li> </ul> <pre><code>$ export NODE_IP=`hostname -i | awk '{print $1}'`\n</code></pre> <ul> <li>Create variables to store the PATH:</li> </ul> <pre><code>DATA_DIR=\"/var/lib/postgresql/16/main\"\nPG_BIN_DIR=\"/usr/lib/postgresql/16/bin\"\n</code></pre> <p>NOTE: Check the path to the data and bin folders on your operating system and change it for the variables accordingly.</p> <ul> <li>Patroni information:</li> </ul> <pre><code>NAMESPACE=\"percona_lab\"\nSCOPE=\"cluster_1\"\n</code></pre> </li> <li> <p>Create the <code>/etc/patroni/patroni.yml</code> configuration file. Add the following configuration for <code>node1</code>:</p> <pre><code>echo \"\nnamespace: ${NAMESPACE}\nscope: ${SCOPE}\nname: ${NODE_NAME}\n\nrestapi:\n    listen: 0.0.0.0:8008\n    connect_address: ${NODE_IP}:8008\n\netcd:\n    host: ${NODE_IP}:2379\n\nbootstrap:\n  # this section will be written into Etcd:/&lt;namespace&gt;/&lt;scope&gt;/config after initializing new cluster\n  dcs:\n      ttl: 30\n      loop_wait: 10\n      retry_timeout: 10\n      maximum_lag_on_failover: 1048576\n      slots:\n          percona_cluster_1:\n          type: physical\n\n      postgresql:\n          use_pg_rewind: true\n          use_slots: true\n          parameters:\n              wal_level: replica\n              hot_standby: \"on\"\n              wal_keep_segments: 10\n              max_wal_senders: 5\n              max_replication_slots: 10\n              wal_log_hints: \"on\"\n              logging_collector: 'on'\n\n  # some desired options for 'initdb'\n  initdb: # Note: It needs to be a list (some options need values, others are switches)\n      - encoding: UTF8\n      - data-checksums\n\n  pg_hba: # Add following lines to pg_hba.conf after running 'initdb'\n      - host replication replicator 127.0.0.1/32 trust\n      - host replication replicator 0.0.0.0/0 md5\n      - host all all 0.0.0.0/0 md5\n      - host all all ::0/0 md5\n\n  # Some additional users which needs to be created after initializing new cluster\n  users:\n      admin:\n          password: qaz123\n          options:\n              - createrole\n              - createdb\n      percona:\n          password: qaz123\n          options:\n              - createrole\n              - createdb \n\npostgresql:\n    cluster_name: cluster_1\n    listen: 0.0.0.0:5432\n    connect_address: ${NODE_IP}:5432\n    data_dir: ${DATADIR}\n    bin_dir: ${PG_BIN_DIR}\n    pgpass: /tmp/pgpass\n    authentication:\n        replication:\n            username: replicator\n            password: replPasswd\n        superuser:\n            username: postgres\n            password: qaz123\n    parameters:\n        unix_socket_directories: \"/var/run/postgresql/\"\n    create_replica_methods:\n        - basebackup\n    basebackup:\n        checkpoint: 'fast'\n\ntags:\n    nofailover: false\n    noloadbalance: false\n    clonefrom: false\n    nosync: false\n\" | sudo tee -a /etc/patroni/patroni.yml\n</code></pre> Patroni configuration file <p>Let\u2019s take a moment to understand the contents of the <code>patroni.yml</code> file. </p> <p>The first section provides the details of the node and its connection ports. After that, we have the <code>etcd</code> service and its port details.</p> <p>Following these, there is a <code>bootstrap</code> section that contains the PostgreSQL configurations and the steps to run once the database is initialized. The <code>pg_hba.conf</code> entries specify all the other nodes that can connect to this node and their authentication mechanism. </p> </li> <li> <p>Check that the systemd unit file <code>patroni.service</code> is created in <code>/etc/systemd/system</code>. If it is created, skip this step. </p> </li> </ol> <p>If it\u2019s not created, create it manually and specify the following contents within:</p> <pre><code>```ini title=\"/etc/systemd/system/patroni.service\"\n[Unit]\nDescription=Runners to orchestrate a high-availability PostgreSQL\nAfter=syslog.target network.target\n\n[Service]\nType=simple\n\nUser=postgres\nGroup=postgres\n\n# Start the patroni process\nExecStart=/bin/patroni /etc/patroni/patroni.yml\n\n# Send HUP to reload from patroni.yml\nExecReload=/bin/kill -s HUP $MAINPID\n\n# only kill the patroni process, not its children, so it will gracefully stop postgres\nKillMode=process\n\n# Give a reasonable amount of time for the server to start up/shut down\nTimeoutSec=30\n\n# Do not restart the service if it crashes, we want to manually inspect database on failure\nRestart=no\n\n[Install]\nWantedBy=multi-user.target\n```\n</code></pre> <ol> <li> <p>Make systemd aware of the new service:</p> <pre><code>$ sudo systemctl daemon-reload\n</code></pre> </li> <li> <p>Now it\u2019s time to start Patroni. You need the following commands on all nodes but not in parallel. Start with the <code>node1</code> first, wait for the service to come to live, and then proceed with the other nodes one-by-one, always waiting for them to sync with the primary node:</p> <pre><code>$ sudo systemctl enable --now patroni\n$ sudo systemctl restart patroni\n</code></pre> </li> </ol> <p>When Patroni starts, it initializes PostgreSQL (because the service is not currently running and the data directory is empty) following the directives in the bootstrap section of the configuration file. </p> <ol> <li> <p>Check the service to see if there are errors:</p> <pre><code>$ sudo journalctl -fu patroni\n</code></pre> <p>A common error is Patroni complaining about the lack of proper entries in the pg_hba.conf file. If you see such errors, you must manually add or fix the entries in that file and then restart the service.</p> <p>Changing the patroni.yml file and restarting the service will not have any effect here because the bootstrap section specifies the configuration to apply when PostgreSQL is first started in the node. It will not repeat the process even if the Patroni configuration file is modified and the service is restarted.</p> </li> <li> <p>Check the cluster:</p> <pre><code>$ patronictl -c /etc/patroni/patroni.yml list $SCOPE\n</code></pre> <p>The output on <code>node1</code> resembles the following:</p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> <p>On the remaining nodes:</p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n| node-2 | 10.0.100.2  | Replica | running |  1 |         0 |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> </li> </ol> <p>If Patroni has started properly, you should be able to locally connect to a PostgreSQL node using the following command:</p> <pre><code>$ sudo psql -U postgres\n</code></pre> <p>The command output is the following:</p> <pre><code>psql (16.0)\nType \"help\" for help.\n\npostgres=#\n</code></pre>"},{"location":"solutions/ha-setup-apt.html#configure-haproxy","title":"Configure HAProxy","text":"<p>HAproxy is the load balancer and the single point of entry to your PostgreSQL cluster for client applications. A client application accesses the HAPpoxy URL and sends its read/write requests there. Behind-the-scene, HAProxy routes write requests to the primary node and read requests - to the secondaries in a round-robin fashion so that no secondary instance is unnecessarily loaded. To make this happen, provide different ports in the HAProxy configuration file. In this deployment, writes are routed to port 5000 and reads  - to port 5001</p> <p>This way, a client application doesn\u2019t know what node in the underlying cluster is the current primary. HAProxy sends connections to a healthy node (as long as there is at least one healthy node available) and ensures that client application requests are never rejected. </p> <ol> <li> <p>Install HAProxy on the <code>HAProxy-demo</code> node:</p> <pre><code>$ sudo apt install percona-haproxy\n</code></pre> </li> <li> <p>The HAProxy configuration file path is: <code>/etc/haproxy/haproxy.cfg</code>. Specify the following configuration in this file.</p> <pre><code>global\n    maxconn 100\n\ndefaults\n    log global\n    mode tcp\n    retries 2\n    timeout client 30m\n    timeout connect 4s\n    timeout server 30m\n    timeout check 5s\n\nlisten stats\n    mode http\n    bind *:7000\n    stats enable\n    stats uri /\n\nlisten primary\n    bind *:5000\n    option httpchk /primary \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n\nlisten standbys\n    balance roundrobin\n    bind *:5001\n    option httpchk /replica \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n</code></pre> <p>HAProxy will use the REST APIs hosted by Patroni to check the health status of each PostgreSQL node and route the requests appropriately. </p> </li> <li> <p>Restart HAProxy:</p> <pre><code>$ sudo systemctl restart haproxy\n</code></pre> </li> <li> <p>Check the HAProxy logs to see if there are any errors:</p> <pre><code>$ sudo journalctl -u haproxy.service -n 100 -f\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#next-steps","title":"Next steps","text":"<p>Configure pgBackRest</p>"},{"location":"solutions/ha-setup-apt.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/ha-setup-yum.html","title":"Deploying PostgreSQL for high availability with Patroni on RHEL or CentOS","text":"<p>This guide provides instructions on how to set up a highly available PostgreSQL cluster with Patroni on Red Hat Enterprise Linux or CentOS. </p>"},{"location":"solutions/ha-setup-yum.html#considerations","title":"Considerations","text":"<ol> <li>This is the example deployment suitable to be used for testing purposes in non-production environments. </li> <li>In this setup ETCD resides on the same hosts as Patroni. In production, consider deploying ETCD cluster on dedicated hosts because ETCD writes every request from the cluster to disk which requires significant amount of disk space. See hardware recommendations for details.</li> <li> <p>For this setup, we use the nodes running on Red Hat Enterprise Linux 8 as the base operating system:</p> Node name Application IP address node1 Patroni, PostgreSQL, ETCD 10.104.0.1 node2 Patroni, PostgreSQL, ETCD 10.104.0.2 node3 Patroni, PostgreSQL, ETCD 10.104.0.3 HAProxy-demo HAProxy 10.104.0.6 </li> </ol> <p>Note</p> <p>Ideally, in a production (or even non-production) setup, the PostgreSQL and ETCD nodes will be within a private subnet without any public connectivity to the Internet, and the HAProxy will be in a different subnet that allows client traffic coming only from a selected IP range. To keep things simple, we have implemented this architecture in a private environment, and each node can access the other by its internal, private IP.  </p>"},{"location":"solutions/ha-setup-yum.html#initial-setup","title":"Initial setup","text":""},{"location":"solutions/ha-setup-yum.html#set-up-hostnames-in-the-etchosts-file","title":"Set up hostnames in the <code>/etc/hosts</code> file","text":"<p>It\u2019s not necessary to have name resolution, but it makes the whole setup more readable and less error prone. Here, instead of configuring a DNS, we use a local name resolution by updating the file <code>/etc/hosts</code>. By resolving their hostnames to their IP addresses, we make the nodes aware of each other\u2019s names and allow their seamless communication. </p> <ol> <li> <p>Run the following command on each node. Change the node name to <code>node1</code>, <code>node2</code> and <code>node3</code> respectively:</p> <pre><code>$ sudo hostnamectl set-hostname node-1\n</code></pre> </li> <li> <p>Modify the <code>/etc/hosts</code> file of each PostgreSQL node to include the hostnames and IP addresses of the remaining nodes. Add the following at the end of the <code>/etc/hosts</code> file on all nodes:</p> node1node2node3HAproxy-demo <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <p>The HAProxy instance should have the name resolution for all the three nodes in its <code>/etc/hosts</code> file. Add the following lines at the end of the file:    </p> <pre><code># Cluster IP and names\n10.104.0.6 HAProxy-demo\n10.104.0.1 node1\n10.104.0.2 node2\n10.104.0.3 node3\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#install-the-software","title":"Install the software","text":"<ol> <li> <p>Install Percona Distribution for PostgreSQL on <code>node1</code>, <code>node2</code> and <code>node3</code> from Percona repository:</p> <ul> <li>Install <code>percona-release</code>.</li> <li> <p>Enable the repository:    </p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages.    </p> </li> </ul> <p>Important</p> <p>Don\u2019t initialize the cluster and start the <code>postgresql</code> service. The cluster initialization and setup are handled by Patroni during the bootsrapping stage.</p> </li> <li> <p>Install some Python and auxiliary packages to help with Patroni and ETCD</p> <pre><code>$ sudo yum install python3-pip python3-devel binutils\n</code></pre> </li> <li> <p>Install ETCD, Patroni, pgBackRest packages. Check platform specific notes for Patroni:</p> <pre><code>$ sudo yum install percona-patroni \\\netcd python3-python-etcd\\\npercona-pgbackrest\n</code></pre> </li> <li> <p>Stop and disable all installed services:</p> <pre><code>$ sudo systemctl stop {etcd,patroni,postgresql}\n$ systemctl disable {etcd,patroni,postgresql}\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-etcd-distributed-store","title":"Configure ETCD distributed store","text":"<p>The distributed configuration store provides a reliable way to store data that needs to be accessed by large scale distributed systems. The most popular implementation of the distributed configuration store is ETCD. ETCD is deployed as a cluster for fault-tolerance and requires an odd number of members (n/2+1) to agree on updates to the cluster state. An ETCD cluster helps establish a consensus among nodes during a failover and manages the configuration for the three PostgreSQL instances.</p> <p>The <code>etcd</code> cluster is first started in one node and then the subsequent nodes are added to the first node using the <code>add</code>command. The configuration is stored in the <code>/etc/etcd/etcd.conf</code> configuration file.</p>"},{"location":"solutions/ha-setup-yum.html#configure-node1","title":"Configure <code>node1</code>","text":"<ol> <li> <p>Backup the <code>etcd.conf</code> file:</p> <pre><code>$ sudo mv /etc/etcd/etcd.conf /etc/etcd/etcd.conf.orig\n</code></pre> </li> <li> <p>Export environment variables to simplify the config file creation</p> <ul> <li>Node name:</li> </ul> <pre><code>$ export NODE_NAME=`hostname -f`\n</code></pre> <ul> <li>Node IP:</li> </ul> <pre><code>$ export NODE_IP=`hostname -i | awk '{print $1}'`\n</code></pre> <ul> <li>Initial cluster token for the ETCD cluster during bootstrap:</li> </ul> <pre><code>$ export ETCD_TOKEN='PostgreSQL_HA_Cluster_1'\n</code></pre> <ul> <li>ETCD data directory:</li> </ul> <pre><code>$ export ETCD_DATA_DIR='/var/lib/etcd/postgresql'\n</code></pre> </li> <li> <p>Modify the <code>/etc/etcd/etcd.conf</code> configuration file:</p> <pre><code>$ echo \"\nETCD_NAME=${NODE_NAME}\nETCD_INITIAL_CLUSTER=\"${NODE_NAME}=http://${NODE_IP}:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\nETCD_INITIAL_CLUSTER_TOKEN=\"${ETCD_TOKEN}\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_DATA_DIR=\"${ETCD_DATA_DIR}\"\nETCD_LISTEN_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://${NODE_IP}:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://${NODE_IP}:2379\"\n\" | sudo tee -a /etc/etcd/etcd.conf \n</code></pre> </li> <li> <p>Start the <code>etcd</code> to apply the changes on <code>node1</code>:</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members on <code>node1</code>.</p> <pre><code>$ sudo etcdctl member list\n</code></pre> <p>The output resembles the following:</p> <pre><code>21d50d7f768f153a: name=default peerURLs=http://10.104.0.5:2380 clientURLs=http://10.104.0.5:2379 isLeader=true\n</code></pre> </li> <li> <p>Add <code>node2</code> to the cluster. Run the following command on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member add node2 http://10.104.0.2:2380\n</code></pre> <p>The output resembles the following one:</p> <pre><code>Added member named node2 with ID 10042578c504d052 to cluster\n\nETCD_NAME=\"node2\"\nETCD_INITIAL_CLUSTER=\"node2=http://10.104.0.2:2380,node1=http://10.104.0.1:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-node2","title":"Configure <code>node2</code>","text":"<ol> <li>Back up the configuration file and export environment variables as described in steps 1-2 of the <code>node1</code> configuration </li> <li> <p>Edit the <code>/etc/etcd/etcd.conf</code> configuration file on <code>node2</code> and add the output from the <code>add</code> command:</p> <pre><code>$ echo \"\nETCD_NAME=\"node2\"\nETCD_INITIAL_CLUSTER=\"node1=http://10.0.100.1:2380,node2=http://10.0.100.2:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\n\nETCD_INITIAL_CLUSTER_TOKEN=\"${ETCD_TOKEN}\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_DATA_DIR=\"${ETCD_DATA_DIR}\"\nETCD_LISTEN_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://${NODE_IP}:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://${NODE_IP}:2379\"\n\" | sudo tee -a /etc/etcd/etcd.conf\n</code></pre> </li> <li> <p>Start the <code>etcd</code> to apply the changes on <code>node2</code>:</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-node3","title":"Configure <code>node3</code>","text":"<ol> <li> <p>Add <code>node3</code> to the cluster. Run the following command on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member add node3 http://10.104.0.3:2380\n</code></pre> </li> <li> <p>On <code>node3</code>, back up the configuration file and export environment variables as described in steps 1-2 of the <code>node1</code> configuration </p> </li> <li> <p>Modify the <code>/etc/etcd/etcd.conf</code> configuration file on <code>node3</code> and add the output from the <code>add</code> command as follows:</p> <pre><code>$ echo \"\nETCD_NAME=node3\nETCD_INITIAL_CLUSTER=\"node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380,node3=http://10.104.0.3:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"  \nETCD_INITIAL_CLUSTER_TOKEN=\"${ETCD_TOKEN}\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_DATA_DIR=\"${ETCD_DATA_DIR}\"\nETCD_LISTEN_PEER_URLS=\"http://${NODE_IP}:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://${NODE_IP}:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://${NODE_IP}:2379\"\n\" | sudo tee -a /etc/etcd/etcd.conf\n</code></pre> </li> <li> <p>Start the <code>etcd</code> service on <code>node3</code>:</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members.</p> <pre><code>$ sudo etcdctl member list\n</code></pre> <p>The output resembles the following:</p> <pre><code>2d346bd3ae7f07c4: name=node2 peerURLs=http://10.104.0.2:2380 clientURLs=http://10.104.0.2:2379 isLeader=false\n8bacb519ebdee8db: name=node3 peerURLs=http://10.104.0.3:2380 clientURLs=http://10.104.0.3:2379 isLeader=false\nc5f52ea2ade25e1b: name=node1 peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379 isLeader=true\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-patroni","title":"Configure Patroni","text":"<p>Run the following commands on all nodes. You can do this in parallel:</p> <ol> <li> <p>Export and create environment variables to simplify the config file creation:</p> <ul> <li>Node name:</li> </ul> <pre><code>$ export NODE_NAME=`hostname -f`\n</code></pre> <ul> <li>Node IP:</li> </ul> <pre><code>$ export NODE_IP=`hostname -i | awk '{print $1}'`\n</code></pre> <ul> <li>Create variables to store the PATH:</li> </ul> <pre><code>DATA_DIR=\"/var/lib/pgsql/data/\"\nPG_BIN_DIR=\"/usr/pgsql-16/bin\"\n</code></pre> <p>NOTE: Check the path to the data and bin folders on your operating system and change it for the variables accordingly.</p> <ul> <li>Patroni information:</li> </ul> <pre><code>NAMESPACE=\"percona_lab\"\nSCOPE=\"cluster_1\n</code></pre> </li> <li> <p>Create the directories required by Patroni</p> <ul> <li>Create the directory to store the configuration file and make it owned by the <code>postgres</code> user.</li> </ul> <pre><code>$ sudo mkdir -p /etc/patroni/\n$ sudo chown -R  postgres:postgres /etc/patroni/\n</code></pre> <ul> <li>Create the data directory to store PostgreSQL data. Change its ownership to the <code>postgres</code> user and restrict the access to it </li> </ul> <pre><code>$ sudo mkdir /data/pgsql -p\n$ sudo chown -R postgres:postgres /data/pgsql\n$ sudo chmod 700 /data/pgsql\n</code></pre> </li> <li> <p>Create the <code>/etc/patroni/patroni.yml</code> configuration file. Add the following configuration:</p> <pre><code>echo \"\nnamespace: ${NAMESPACE}\nscope: ${SCOPE}\nname: ${NODE_NAME}\n\nrestapi:\n    listen: 0.0.0.0:8008\n    connect_address: ${NODE_IP}:8008\n\netcd:\n    host: ${NODE_IP}:2379\n\nbootstrap:\n  # this section will be written into Etcd:/&lt;namespace&gt;/&lt;scope&gt;/config after initializing new cluster\n  dcs:\n      ttl: 30\n      loop_wait: 10\n      retry_timeout: 10\n      maximum_lag_on_failover: 1048576\n      slots:\n          percona_cluster_1:\n          type: physical\n\n      postgresql:\n          use_pg_rewind: true\n          use_slots: true\n          parameters:\n              wal_level: replica\n              hot_standby: \"on\"\n              wal_keep_segments: 10\n              max_wal_senders: 5\n              max_replication_slots: 10\n              wal_log_hints: \"on\"\n              logging_collector: 'on'\n\n  # some desired options for 'initdb'\n  initdb: # Note: It needs to be a list (some options need values, others are switches)\n      - encoding: UTF8\n      - data-checksums\n\n  pg_hba: # Add following lines to pg_hba.conf after running 'initdb'\n      - host replication replicator 127.0.0.1/32 trust\n      - host replication replicator 0.0.0.0/0 md5\n      - host all all 0.0.0.0/0 md5\n      - host all all ::0/0 md5\n\n  # Some additional users which needs to be created after initializing new cluster\n  users:\n      admin:\n          password: qaz123\n          options:\n              - createrole\n              - createdb\n      percona:\n          password: qaz123\n          options:\n              - createrole\n              - createdb \n\npostgresql:\n    cluster_name: cluster_1\n    listen: 0.0.0.0:5432\n    connect_address: ${NODE_IP}:5432\n    data_dir: ${DATADIR}\n    bin_dir: ${PG_BIN_DIR}\n    pgpass: /tmp/pgpass\n    authentication:\n        replication:\n            username: replicator\n            password: replPasswd\n        superuser:\n            username: postgres\n            password: qaz123\n    parameters:\n        unix_socket_directories: \"/var/run/postgresql/\"\n    create_replica_methods:\n        - basebackup\n    basebackup:\n        checkpoint: 'fast'\n\ntags:\n    nofailover: false\n    noloadbalance: false\n    clonefrom: false\n    nosync: false\n\" | sudo tee -a /etc/patroni/patroni.yml\n</code></pre> </li> <li> <p>Check that the systemd unit file <code>patroni.service</code> is created in <code>/etc/systemd/system</code>. If it is created, skip this step. </p> <p>If it\u2019s not created, create it manually and specify the following contents within:</p> /etc/systemd/system/patroni.service<pre><code>[Unit]\nDescription=Runners to orchestrate a high-availability PostgreSQL\nAfter=syslog.target network.target \n\n[Service]\nType=simple \n\nUser=postgres\nGroup=postgres \n\n# Start the patroni process\nExecStart=/bin/patroni /etc/patroni/patroni.yml \n\n# Send HUP to reload from patroni.yml\nExecReload=/bin/kill -s HUP $MAINPID \n\n# only kill the patroni process, not its children, so it will gracefully stop postgres\nKillMode=process \n\n# Give a reasonable amount of time for the server to start up/shut down\nTimeoutSec=30 \n\n# Do not restart the service if it crashes, we want to manually inspect database on failure\nRestart=no \n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Make <code>systemd</code> aware of the new service:</p> <pre><code>$ sudo systemctl daemon-reload\n</code></pre> </li> <li> <p>Now it\u2019s time to start Patroni. You need the following commands on all nodes but not in parallel. Start with the <code>node1</code> first, wait for the service to come to live, and then proceed with the other nodes one-by-one, always waiting for them to sync with the primary node:</p> <pre><code>$ sudo systemctl enable --now patroni\n$ sudo systemctl restart patroni\n</code></pre> </li> </ol> <p>When Patroni starts, it initializes PostgreSQL (because the service is not currently running and the data directory is empty) following the directives in the bootstrap section of the configuration file. </p> <ol> <li> <p>Check the service to see if there are errors:</p> <pre><code>$ sudo journalctl -fu patroni\n</code></pre> <p>A common error is Patroni complaining about the lack of proper entries in the pg_hba.conf file. If you see such errors, you must manually add or fix the entries in that file and then restart the service.</p> <p>Changing the patroni.yml file and restarting the service will not have any effect here because the bootstrap section specifies the configuration to apply when PostgreSQL is first started in the node. It will not repeat the process even if the Patroni configuration file is modified and the service is restarted. </p> <p>If Patroni has started properly, you should be able to locally connect to a PostgreSQL node using the following command:</p> <pre><code>$ sudo psql -U postgres\n\npsql (16.0)\nType \"help\" for help.\n\npostgres=#\n</code></pre> </li> <li> <p>When all nodes are up and running, you can check the cluster status using the following command:</p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml list\n</code></pre> <p>The output on <code>node1</code> resembles the following: </p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> <p>On the remaining nodes:</p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n| node-2 | 10.0.100.2  | Replica | running |  1 |         0 |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-haproxy","title":"Configure HAProxy","text":"<p>HAproxy is the load balancer and the single point of entry to your PostgreSQL cluster for client applications. A client application accesses the HAPpoxy URL and sends its read/write requests there. Behind-the-scene, HAProxy routes write requests to the primary node and read requests - to the secondaries in a round-robin fashion so that no secondary instance is unnecessarily loaded. To make this happen, provide different ports in the HAProxy configuration file. In this deployment, writes are routed to port 5000 and reads  - to port 5001</p> <p>This way, a client application doesn\u2019t know what node in the underlying cluster is the current primary. HAProxy sends connections to a healthy node (as long as there is at least one healthy node available) and ensures that client application requests are never rejected. </p> <ol> <li> <p>Install HAProxy on the <code>HAProxy-demo</code> node:</p> <pre><code>$ sudo yum install percona-haproxy\n</code></pre> </li> <li> <p>The HAProxy configuration file path is: <code>/etc/haproxy/haproxy.cfg</code>. Specify the following configuration in this file.</p> <pre><code>global\n    maxconn 100\n\ndefaults\n    log global\n    mode tcp\n    retries 2\n    timeout client 30m\n    timeout connect 4s\n    timeout server 30m\n    timeout check 5s\n\nlisten stats\n    mode http\n    bind *:7000\n    stats enable\n    stats uri /\n\nlisten primary\n    bind *:5000\n    option httpchk /primary \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n\nlisten standbys\n    balance roundrobin\n    bind *:5001\n    option httpchk /replica \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n</code></pre> <p>HAProxy will use the REST APIs hosted by Patroni to check the health status of each PostgreSQL node and route the requests appropriately. </p> </li> <li> <p>Enable a SELinux boolean to allow HAProxy to bind to non standard ports:</p> <pre><code>$ sudo setsebool -P haproxy_connect_any on\n</code></pre> </li> <li> <p>Restart HAProxy:</p> <pre><code>$ sudo systemctl restart haproxy\n</code></pre> </li> <li> <p>Check the HAProxy logs to see if there are any errors:</p> <pre><code>$ sudo journalctl -u haproxy.service -n 100 -f\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#next-steps","title":"Next steps","text":"<p>Configure pgBackRest</p>"},{"location":"solutions/ha-setup-yum.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/ha-test.html","title":"Testing the Patroni PostgreSQL Cluster","text":"<p>This document covers the following scenarios to test the PostgreSQL cluster:</p> <ul> <li>replication, </li> <li>connectivity, </li> <li>failover, and </li> <li>manual switchover.</li> </ul>"},{"location":"solutions/ha-test.html#testing-replication","title":"Testing replication","text":"<ol> <li> <p>Connect to the cluster and establish the <code>psql</code> session from a client machine that can connect to the HAProxy node. Use the HAProxy-demo node\u2019s public IP address:</p> <pre><code>$ psql -U postgres -h 134.209.111.138 -p 5000\n</code></pre> </li> <li> <p>Run the following commands to create a table and insert a few rows:</p> <pre><code>CREATE TABLE customer(name text,age integer);\nINSERT INTO CUSTOMER VALUES('john',30);\nINSERT INTO CUSTOMER VALUES('dawson',35);\n</code></pre> </li> <li> <p>To ensure that the replication is working, we can log in to each PostgreSQL node and run a simple SQL statement against the locally running instance:</p> <pre><code>$ sudo psql -U postgres -c \"SELECT * FROM CUSTOMER;\"\n</code></pre> <p>The results on each node should be the following:</p> <pre><code>  name  | age\n--------+-----\n john   |  30\n dawson |  35\n(2 rows)\n</code></pre> </li> </ol>"},{"location":"solutions/ha-test.html#testing-failover","title":"Testing failover","text":"<p>In a proper setup, client applications won\u2019t have issues connecting to the cluster, even if one or even two of the nodes go down. We will test the cluster for failover in the following scenarios:</p>"},{"location":"solutions/ha-test.html#scenario-1-intentionally-stop-the-postgresql-on-the-primary-node-and-verify-access-to-postgresql","title":"Scenario 1. Intentionally stop the PostgreSQL on the primary node and verify access to PostgreSQL.","text":"<ol> <li> <p>Run the following command on any node to check the current cluster status:</p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml list\n</code></pre> <p>Output:</p> <pre><code>+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Leader  | running |  1 |           |\n| node2  | node2 | Replica | running |  1 |         0 |\n| node3  | node3 | Replica | running |  1 |         0 |\n+--------+-------+---------+---------+----+-----------+\n</code></pre> </li> <li> <p><code>node1</code> is the current leader. Stop Patroni in <code>node1</code> to see how it changes the cluster:</p> <pre><code>$ sudo systemctl stop patroni\n</code></pre> </li> <li> <p>Once the service stops in <code>node1</code>, check the logs in <code>node2</code> and <code>node3</code> using the following command: </p> <pre><code>$ sudo journalctl -u patroni.service -n 100 -f\n</code></pre> Output <pre><code>Sep 23 14:18:13 node03 patroni[10042]: 2021-09-23 14:18:13,905 INFO: no action. I am a secondary (node3) and following a leader (node1)\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,011 INFO: Got response from node2 http://node2:8008/patroni: {\"state\": \"running\", \"postprimary_start_time\": \"2021-09-23 12:50:29.460027+00:00\", \"role\": \"replica\", \"server_version\": 130003, \"cluster_unlocked\": true, \"xlog\": {\"received_location\": 67219152, \"replayed_location\": 67219152, \"replayed_timestamp\": \"2021-09-23 13:19:50.329387+00:00\", \"paused\": false}, \"timeline\": 1, \"database_system_identifier\": \"7011110722654005156\", \"patroni\": {\"version\": \"2.1.0\", \"scope\": \"stampede1\"}}\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,031 WARNING: Request failed to node1: GET http://node1:8008/patroni (HTTPConnectionPool(host='node1', port=8008): Max retries exceeded with url: /patroni (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))))\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,038 INFO: Software Watchdog activated with 25 second timeout, timing slack 15 seconds\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,043 INFO: promoted self to leader by acquiring session lock\nSep 23 14:18:20 node03 patroni[13641]: server promoting\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,049 INFO: cleared rewind state after becoming the leader\nSep 23 14:18:21 node03 patroni[10042]: 2021-09-23 14:18:21,101 INFO: no action. I am (node3) the leader with the lock\nSep 23 14:18:21 node03 patroni[10042]: 2021-09-23 14:18:21,117 INFO: no action. I am (node3) the leader with the lock\nSep 23 14:18:31 node03 patroni[10042]: 2021-09-23 14:18:31,114 INFO: no action. I am (node3) the leader with the lock\n...\n</code></pre> <p>The logs in <code>node3</code> show that the requests to <code>node1</code> are failing, the watchdog is coming into action, and <code>node3</code> is promoting itself as the leader:</p> </li> <li> <p>Verify that you can still access the cluster through the HAProxy instance and read data:</p> <pre><code>$ psql -U postgres -h 10.104.0.3 -p 5000 -c \"SELECT * FROM CUSTOMER;\"\n\n  name  | age\n--------+-----\n john   |  30\n dawson |  35\n(2 rows)\n</code></pre> </li> <li> <p>Restart the Patroni service in <code>node1</code></p> <pre><code>$ sudo systemctl start patroni\n</code></pre> </li> <li> <p>Check the current cluster status:  </p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml list\n</code></pre> <p>Output:</p> <pre><code>+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Replica | running |  2 |         0 |\n| node2  | node2 | Replica | running |  2 |         0 |\n| node3  | node3 | Leader  | running |  2 |           |\n+--------+-------+---------+---------+----+-----------+\n</code></pre> </li> </ol> <p>As we see, <code>node3</code> remains the leader and the rest are replicas.</p>"},{"location":"solutions/ha-test.html#scenario-2-abrupt-machine-shutdown-or-power-outage","title":"Scenario 2. Abrupt machine shutdown or power outage","text":"<p>To emulate the power outage, let\u2019s kill the service in <code>node3</code> and see what happens in <code>node1</code> and <code>node2</code>. </p> <ol> <li> <p>Identify the process ID of Patroni and then kill it with a <code>-9</code> switch. </p> <pre><code>$ ps aux | grep -i patroni\n\npostgres   10042  0.1  2.1 647132 43948 ?        Ssl  12:50   0:09 /usr/bin/python3 /usr/bin/patroni /etc/patroni/patroni.yml\n\n$ sudo kill -9 10042\n</code></pre> </li> <li> <p>Check the logs on <code>node2</code>: </p> <pre><code>$ sudo journalctl -u patroni.service -n 100 -f\n</code></pre> Output <pre><code>Sep 23 14:40:41 node02 patroni[10577]: 2021-09-23 14:40:41,656 INFO: no action. I am a secondary (node2) and following a leader (node3)\n\u2026\nSep 23 14:41:01 node02 patroni[10577]: 2021-09-23 14:41:01,373 INFO: Got response from node1 http://node1:8008/patroni: {\"state\": \"running\", \"postprimary_start_time\": \"2021-09-23 14:25:30.076762+00:00\", \"role\": \"replica\", \"server_version\": 130003, \"cluster_unlocked\": true, \"xlog\": {\"received_location\": 67221352, \"replayed_location\": 67221352, \"replayed_timestamp\": null, \"paused\": false}, \"timeline\": 2, \"database_system_identifier\": \"7011110722654005156\", \"patroni\": {\"version\": \"2.1.0\", \"scope\": \"stampede1\"}}\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,364 WARNING: Request failed to node3: GET http://node3:8008/patroni (HTTPConnectionPool(host='node3', port=8008): Max retries exceeded with url: /patroni (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPConnection object at 0x7f57e06dffa0&gt;, 'Connection to node3 timed out. (connect timeout=2)')))\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,373 INFO: Software Watchdog activated with 25 second timeout, timing slack 15 seconds\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,385 INFO: promoted self to leader by acquiring session lock\nSep 23 14:41:03 node02 patroni[15478]: server promoting\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,397 INFO: cleared rewind state after becoming the leader\nSep 23 14:41:04 node02 patroni[10577]: 2021-09-23 14:41:04,450 INFO: no action. I am (node2) the leader with the lock\nSep 23 14:41:04 node02 patroni[10577]: 2021-09-23 14:41:04,475 INFO: no action. I am (node2) the leader with the lock\n\u2026\n\u2026 \n</code></pre> <p><code>node2</code> realizes that the leader is dead, and promotes itself as the leader.</p> </li> <li> <p>Try accessing the cluster using the HAProxy endpoint at any point in time between these operations. The cluster is still accepting connections.</p> </li> </ol>"},{"location":"solutions/ha-test.html#manual-switchover","title":"Manual switchover","text":"<p>Typically, a manual switchover is needed for planned downtime to perform maintenance activity on the leader node. Patroni provides the <code>switchover</code> command to manually switch over from the leader node. </p> <p>Run the following command on <code>node2</code> (the current leader node):</p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml switchover\n</code></pre> <p>Patroni asks the name of the current primary node and then the node that should take over as the switched-over primary. You can also specify the time at which the switchover should happen. To trigger the process immediately, specify the value now:</p> <pre><code>primary [node2]: node2\nCandidate ['node1', 'node3'] []: node1\nWhen should the switchover take place (e.g. 2021-09-23T15:56 )  [now]: now\nCurrent cluster topology\n+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Replica | running |  3 |         0 |\n| node2  | node2 | Leader  | running |  3 |           |\n| node3  | node3 | Replica | stopped |    |   unknown |\n+--------+-------+---------+---------+----+-----------+\nAre you sure you want to switchover cluster stampede1, demoting current primary node2? [y/N]: y\n2021-09-23 14:56:40.54009 Successfully switched over to \"node1\"\n+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Leader  | running |  3 |           |\n| node2  | node2 | Replica | stopped |    |   unknown |\n| node3  | node3 | Replica | stopped |    |   unknown |\n+--------+-------+---------+---------+----+-----------+\n</code></pre> <p>Restart the Patroni service in <code>node2</code> (after the \u201cplanned maintenance\u201d). The node rejoins the cluster as a secondary.</p>"},{"location":"solutions/ha-test.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/high-availability.html","title":"High Availability in PostgreSQL with Patroni","text":"<p>PostgreSQL has been widely adopted as a modern, high-performance transactional database. A highly available PostgreSQL cluster can withstand failures caused by network outages, resource saturation, hardware failures, operating system crashes or unexpected reboots. Such cluster is often a critical component of the enterprise application landscape, where four nines of availability is a minimum requirement. </p> <p>There are several methods to achieve high availability in PostgreSQL. This solution document provides Patroni - the open-source extension to facilitate and manage the deployment of high availability in PostgreSQL.</p> High availability methods <p>There are several native methods for achieving high availability with PostgreSQL:</p> <ul> <li>shared disk failover, </li> <li>file system replication, </li> <li>trigger-based replication, </li> <li>statement-based replication, </li> <li>logical replication, </li> <li>Write-Ahead Log (WAL) shipping, and</li> <li>streaming replication</li> </ul>"},{"location":"solutions/high-availability.html#streaming-replication","title":"Streaming replication","text":"<p>Streaming replication is part of Write-Ahead Log shipping, where changes to the WALs are immediately made available to standby replicas. With this approach, a standby instance is always up-to-date with changes from the primary node and can assume the role of primary in case of a failover.</p>"},{"location":"solutions/high-availability.html#why-native-streaming-replication-is-not-enough","title":"Why native streaming replication is not enough","text":"<p>Although the native streaming replication in PostgreSQL supports failing over  to the primary node, it lacks some key features expected from a truly highly-available solution. These include:</p> <ul> <li>No consensus-based promotion of a \u201cleader\u201d node during a failover</li> <li>No decent capability for monitoring cluster status </li> <li>No automated way to bring back the failed primary node to the cluster</li> <li>A manual or scheduled switchover is not easy to manage </li> </ul> <p>To address these shortcomings, there are a multitude of third-party, open-source extensions for PostgreSQL. The challenge for a database administrator here is to select the right utility for the current scenario. </p> <p>Percona Distribution for PostgreSQL solves this challenge by providing the Patroni extension for achieving PostgreSQL high availability.</p>"},{"location":"solutions/high-availability.html#patroni","title":"Patroni","text":"<p>Patroni is a template for you to create your own customized, high-availability solution using Python and - for maximum accessibility - a distributed configuration store like ZooKeeper, etcd, Consul or Kubernetes. </p>"},{"location":"solutions/high-availability.html#key-benefits-of-patroni","title":"Key benefits of Patroni:","text":"<ul> <li>Continuous monitoring and automatic failover</li> <li>Manual/scheduled switchover with a single command</li> <li>Built-in automation for bringing back a failed node to cluster again.</li> <li>REST APIs for entire cluster configuration and further tooling.</li> <li>Provides infrastructure for transparent application failover</li> <li>Distributed consensus for every action and configuration.</li> <li>Integration with Linux watchdog for avoiding split-brain syndrome.</li> </ul>"},{"location":"solutions/high-availability.html#architecture-layout","title":"Architecture layout","text":"<p>The following diagram shows the architecture of a three-node PostgreSQL cluster with a single-leader node. </p> <p></p>"},{"location":"solutions/high-availability.html#components","title":"Components","text":"<p>The components in this architecture are:</p> <ul> <li>PostgreSQL nodes </li> <li> <p>Patroni - a template for configuring a highly available PostgreSQL cluster.</p> </li> <li> <p>ETCD - a Distributed Configuration store that stores the state of the PostgreSQL cluster. </p> </li> <li> <p>HAProxy - the load balancer for the cluster and is the single point of entry to client applications. </p> </li> <li> <p>pgBackRest - the backup and restore solution for PostgreSQL</p> </li> <li> <p>Percona Monitoring and Management (PMM) - the solution to monitor the health of your cluster </p> </li> </ul>"},{"location":"solutions/high-availability.html#how-components-work-together","title":"How components work together","text":"<p>Each PostgreSQL instance in the cluster maintains consistency with other members through streaming replication. Each instance hosts Patroni - a cluster manager that monitors the cluster health. Patroni relies on the operational ETCD cluster to store the cluster configuration and sensitive data about the cluster health there. </p> <p>Patroni periodically sends heartbeat requests with the cluster status to ETCD. ETCD writes this information to disk and sends the response back to Patroni. If the current primary fails to renew its status as leader within the specified timeout, Patroni updates the state change in ETCD, which uses this information to elect the new primary and keep the cluster up and running.</p> <p>The connections to the cluster do not happen directly to the database nodes but are routed via a connection proxy like HAProxy. This proxy determines the active node by querying the Patroni REST API.</p>"},{"location":"solutions/high-availability.html#next-steps","title":"Next steps","text":"<p>Deploy on Debian or Ubuntu Deploy on RHEL or derivatives</p>"},{"location":"solutions/high-availability.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/pgbackrest.html","title":"pgBackRest setup","text":"<p>pgBackRest is a backup tool used to perform PostgreSQL database backup, archiving, restoration, and point-in-time recovery. While it can be used for local backups, this procedure shows how to deploy a pgBackRest server running on a dedicated host and how to configure PostgreSQL servers to use it for backups and archiving.</p> <p>You also need a backup storage to store the backups. It can either be a remote storage such as AWS S3, S3-compatible storages or Azure blob storage, or a filesystem-based one. </p>"},{"location":"solutions/pgbackrest.html#configure-backup-server","title":"Configure backup server","text":"<p>To make things easier when working with some templates, run the commands below  as the root user. Run the following command to switch to the root user:</p> <pre><code>$ sudo su -\n</code></pre>"},{"location":"solutions/pgbackrest.html#install-pgbackrest","title":"Install pgBackRest","text":"<ol> <li> <p>Enable the repository with percona-release</p> <pre><code>$ percona-release setup ppg-16       \n</code></pre> </li> <li> <p>Install pgBackRest package</p> Debian/UbuntuRHEL/derivatives <pre><code>$ apt install percona-pgbackrest\n</code></pre> <pre><code>$ yum install percona-pgbackrest\n</code></pre> </li> </ol>"},{"location":"solutions/pgbackrest.html#create-the-configuration-file","title":"Create the configuration file","text":"<ol> <li> <p>Create environment variables to simplify the config file creation:</p> <pre><code>export SRV_NAME=\"bkp-srv\"\nexport NODE1_NAME=\"node-1\"\nexport NODE2_NAME=\"node-2\"\nexport NODE3_NAME=\"node-3\"\nexport CA_PATH=\"/etc/ssl/certs/pg_ha\"\n</code></pre> </li> <li> <p>Create the <code>pgBackRest</code> repository, if necessary</p> <p>A repository is where <code>pgBackRest</code> stores backups. In this example, the backups will be saved to <code>/var/lib/pgbackrest</code>.</p> <p>This directory is usually created during pgBackRest\u2019s installation process. If it\u2019s not there already, create it as follows:</p> <pre><code>$ mkdir -p /var/lib/pgbackrest\n$ chmod 750 /var/lib/pgbackrest\n$ chown postgres:postgres /var/lib/pgbackrest\n</code></pre> </li> <li> <p>The default <code>pgBackRest</code> configuration file location is <code>/etc/pgbackrest/pgbackrest.conf</code>, but some systems continue to use the old path, <code>/etc/pgbackrest.conf</code>, which remains a valid alternative. If the former is not present in your system, create the latter.</p> <p>Access the file\u2019s parent directory (either <code>cd /etc/</code> or <code>cd /etc/pgbackrest/</code>), and make a backup copy of it:</p> <pre><code>$ cp pgbackrest.conf pgbackrest.conf.bak\n</code></pre> <p>Then use the following command to create a basic configuration file using the environment variables we created in a previous step:</p> Debian/UbuntuRHEL/derivatives <pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global] \n\n# Server repo details\nrepo1-path=/var/lib/pgbackrest \n\n### Retention ###\n#  - repo1-retention-archive-type\n#  - If set to full pgBackRest will keep archive logs for the number of full backups defined by repo-retention-archive\nrepo1-retention-archive-type=full \n\n# repo1-retention-archive\n#  - Number of backups worth of continuous WAL to retain\n#  - NOTE: WAL segments required to make a backup consistent are always retained until the backup is expired regardless of how this option is configured\n#  - If this value is not set and repo-retention-full-type is count (default), then the archive to expire will default to the repo-retention-full\n# repo1-retention-archive=2 \n\n# repo1-retention-full\n#  - Full backup retention count/time.\n#  - When a full backup expires, all differential and incremental backups associated with the full backup will also expire. \n#  - When the option is not defined a warning will be issued. \n#  - If indefinite retention is desired then set the option to the max value. \nrepo1-retention-full=4 \n\n# Server general options\nprocess-max=12\nlog-level-console=info\n#log-level-file=debug\nlog-level-file=info\nstart-fast=y\ndelta=y\nbackup-standby=y \n\n########## Server TLS options ##########\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${SRV_NAME}.crt\ntls-server-key-file=${CA_PATH}/${SRV_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt \n\n### Auth entry ###\ntls-server-auth=${NODE1_NAME}=cluster_1\ntls-server-auth=${NODE2_NAME}=cluster_1\ntls-server-auth=${NODE3_NAME}=cluster_1 \n\n### Clusters and nodes ###\n[cluster_1]\npg1-host=${NODE1_NAME}\npg1-host-port=8432\npg1-port=5432\npg1-path=/var/lib/postgresql/16/main\npg1-host-type=tls\npg1-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg1-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg1-host-ca-file=${CA_PATH}/ca.crt\npg1-socket-path=/var/run/postgresql \n\npg2-host=${NODE2_NAME}\npg2-host-port=8432\npg2-port=5432\npg2-path=/var/lib/postgresql/16/main\npg2-host-type=tls\npg2-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg2-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg2-host-ca-file=${CA_PATH}/ca.crt\npg2-socket-path=/var/run/postgresql \n\npg3-host=${NODE3_NAME}\npg3-host-port=8432\npg3-port=5432\npg3-path=/var/lib/postgresql/16/main\npg3-host-type=tls\npg3-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg3-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg3-host-ca-file=${CA_PATH}/ca.crt\npg3-socket-path=/var/run/postgresql\nEOF\n</code></pre> <pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global] \n\n# Server repo details\nrepo1-path=/var/lib/pgbackrest \n\n### Retention ###\n#  - repo1-retention-archive-type\n#  - If set to full pgBackRest will keep archive logs for the number of full backups defined by repo-retention-archive\nrepo1-retention-archive-type=full \n\n# repo1-retention-archive\n#  - Number of backups worth of continuous WAL to retain\n#  - NOTE: WAL segments required to make a backup consistent are always retained until the backup is expired regardless of how this option is configured\n#  - If this value is not set and repo-retention-full-type is count (default), then the archive to expire will default to the repo-retention-full\n# repo1-retention-archive=2 \n\n# repo1-retention-full\n#  - Full backup retention count/time.\n#  - When a full backup expires, all differential and incremental backups associated with the full backup will also expire. \n#  - When the option is not defined a warning will be issued. \n#  - If indefinite retention is desired then set the option to the max value. \nrepo1-retention-full=4 \n\n# Server general options\nprocess-max=12\nlog-level-console=info\n#log-level-file=debug\nlog-level-file=info\nstart-fast=y\ndelta=y\nbackup-standby=y \n\n########## Server TLS options ##########\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${SRV_NAME}.crt\ntls-server-key-file=${CA_PATH}/${SRV_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt \n\n### Auth entry ###\ntls-server-auth=${NODE1_NAME}=cluster_1\ntls-server-auth=${NODE2_NAME}=cluster_1\ntls-server-auth=${NODE3_NAME}=cluster_1 \n\n### Clusters and nodes ###\n[cluster_1]\npg1-host=${NODE1_NAME}\npg1-host-port=8432\npg1-port=5432\npg1-path=/var/lib/pgsql/16/data\npg1-host-type=tls\npg1-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg1-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg1-host-ca-file=${CA_PATH}/ca.crt\npg1-socket-path=/var/run/postgresql \n\npg2-host=${NODE2_NAME}\npg2-host-port=8432\npg2-port=5432\npg2-path=/var/lib/pgsql/16/data\npg2-host-type=tls\npg2-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg2-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg2-host-ca-file=${CA_PATH}/ca.crt\npg2-socket-path=/var/run/postgresql \n\npg3-host=${NODE3_NAME}\npg3-host-port=8432\npg3-port=5432\npg3-path=/var/lib/pgsql/16/data\npg3-host-type=tls\npg3-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg3-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg3-host-ca-file=${CA_PATH}/ca.crt\npg3-socket-path=/var/run/postgresql\nEOF\n</code></pre> <p>NOTE: The option <code>backup-standby=y</code> above indicates the backups should be taken from a standby server. If you are operating with a primary only, or if your secondaries are not configured with <code>pgBackRest</code>, set this option to <code>n</code>.</p> </li> </ol>"},{"location":"solutions/pgbackrest.html#create-the-certificate-files","title":"Create the certificate files","text":"<ol> <li> <p>Create the folder to store the certificates:</p> <pre><code>$ mkdir -p ${CA_PATH}\n</code></pre> </li> <li> <p>Create the certificates and keys</p> <pre><code>$ openssl req -new -x509 -days 365 -nodes -out ${CA_PATH}/ca.crt -keyout ${CA_PATH}/ca.key -subj \"/CN=root-ca\"\n</code></pre> </li> <li> <p>Create the certificate for the backup and the PostgreSQL servers</p> <pre><code>$ for node in ${SRV_NAME} ${NODE1_NAME} ${NODE2_NAME} ${NODE3_NAME}\ndo\nopenssl req -new -nodes -out ${CA_PATH}/$node.csr -keyout ${CA_PATH}/$node.key -subj \"/CN=$node\";\ndone\n</code></pre> </li> <li> <p>Sign the certificates with the <code>root-ca</code> key</p> <pre><code>$ for node in ${SRV_NAME} ${NODE1_NAME} ${NODE2_NAME} ${NODE3_NAME}\ndo\nopenssl x509 -req -in ${CA_PATH}/$node.csr -days 365 -CA ${CA_PATH}/ca.crt -CAkey ${CA_PATH}/ca.key -CAcreateserial -out ${CA_PATH}/$node.crt;\ndone\n</code></pre> </li> <li> <p>Remove temporary files, set ownership of the remaining files to the <code>postgres</code> user, and restrict their access:</p> <pre><code>$ rm -f ${CA_PATH}/*.csr\n$ chown postgres:postgres -R ${CA_PATH}\n$ chmod 0600 ${CA_PATH}/*\n</code></pre> </li> </ol>"},{"location":"solutions/pgbackrest.html#create-the-pgbackrest-daemon-service","title":"Create the <code>pgbackrest</code> daemon service","text":"<ol> <li> <p>Create the <code>systemd</code> unit file at the path <code>/etc/systemd/system/pgbackrest.service</code></p> /etc/systemd/system/pgbackrest.service<pre><code>[Unit]\nDescription=pgBackRest Server\nAfter=network.target\n\n[Service]\nType=simple\nUser=postgres\nRestart=always\nRestartSec=1\nExecStart=/usr/bin/pgbackrest server\n#ExecStartPost=/bin/sleep 3\n#ExecStartPost=/bin/bash -c \"[ ! -z $MAINPID ]\"\nExecReload=/bin/kill -HUP $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Reload, start, and enable the service</p> <pre><code>$ systemctl daemon-reload\n$ systemctl start pgbackrest.service\n$ systemctl enable pgbackrest.service\n</code></pre> </li> </ol>"},{"location":"solutions/pgbackrest.html#configure-database-servers","title":"Configure database servers","text":"<p>Run the following commands on <code>node1</code>, <code>node2</code>, and <code>node3</code>.</p> <ol> <li> <p>Install pgBackRest package</p> Debian/UbuntuRHEL/derivatives <pre><code>$ apt install percona-pgbackrest\n</code></pre> <p>```{.bash data-prompt=\u201d$\u201d} $ yum install percona-pgbackrest</p> </li> <li> <p>Export environment variables to simplify the config file creation:</p> <pre><code>$ export NODE_NAME=`hostname -f`\n$ export SRV_NAME=\"bkp-srv\"\n$ export CA_PATH=\"/etc/ssl/certs/pg_ha\"\n</code></pre> </li> <li> <p>Create the certificates folder:</p> <pre><code>$ mkdir -p ${CA_PATH}\n</code></pre> </li> <li> <p>Copy the <code>.crt</code>, <code>.key</code> certificate files and the <code>ca.crt</code> file from the backup server where they were created to every respective node. Then change the ownership to the <code>postgres</code> user and restrict their access. Use the following commands to achieve this:</p> <pre><code>$ scp ${SRV_NAME}:${CA_PATH}/{$NODE_NAME.crt,$NODE_NAME.key,ca.crt} ${CA_PATH}/\n$ chown postgres:postgres -R ${CA_PATH}\n$ chmod 0600 ${CA_PATH}/* \n</code></pre> </li> <li> <p>Edit or create the configuration file which, as explained above, can be either at the <code>/etc/pgbackrest/pgbackrest.conf</code> or <code>/etc/pgbackrest.conf</code> path:</p> Debian/UbuntuRHEL/derivatives pgbackrest.conf<pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global]\nrepo1-host=${SRV_NAME}\nrepo1-host-user=postgres\nrepo1-host-type=tls\nrepo1-host-cert-file=${CA_PATH}/${NODE_NAME}.crt\nrepo1-host-key-file=${CA_PATH}/${NODE_NAME}.key\nrepo1-host-ca-file=${CA_PATH}/ca.crt\n\n# general options\nprocess-max=16\nlog-level-console=info\nlog-level-file=debug\n\n# tls server options\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${NODE_NAME}.crt\ntls-server-key-file=${CA_PATH}/${NODE_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt\ntls-server-auth=${SRV_NAME}=cluster_1\n\n[cluster_1]\npg1-path=/var/lib/postgresql/16/main\nEOF\n</code></pre> pgbackrest.conf<pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global]\nrepo1-host=${SRV_NAME}\nrepo1-host-user=postgres\nrepo1-host-type=tls\nrepo1-host-cert-file=${CA_PATH}/${NODE_NAME}.crt\nrepo1-host-key-file=${CA_PATH}/${NODE_NAME}.key\nrepo1-host-ca-file=${CA_PATH}/ca.crt\n\n# general options\nprocess-max=16\nlog-level-console=info\nlog-level-file=debug\n\n# tls server options\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${NODE_NAME}.crt\ntls-server-key-file=${CA_PATH}/${NODE_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt\ntls-server-auth=${SRV_NAME}=cluster_1\n\n[cluster_1]\npg1-path=/var/lib/pgsql/16/data\nEOF\n</code></pre> </li> <li> <p>Create the pgbackrest <code>systemd</code> unit file at the path <code>/etc/systemd/system/pgbackrest.service</code></p> /etc/systemd/system/pgbackrest.service<pre><code>[Unit]\nDescription=pgBackRest Server\nAfter=network.target\n\n[Service]\nType=simple\nUser=postgres\nRestart=always\nRestartSec=1\nExecStart=/usr/bin/pgbackrest server\n#ExecStartPost=/bin/sleep 3\n#ExecStartPost=/bin/bash -c \"[ ! -z $MAINPID ]\"\nExecReload=/bin/kill -HUP $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Reload, start, and enable the service</p> <pre><code>$ systemctl daemon-reload\n$ systemctl start pgbackrest\n$ systemctl enable pgbackrest\n</code></pre> <p>The pgBackRest daemon listens on port <code>8432</code> by default:</p> <pre><code>$ netstat -taunp\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      1/systemd           \ntcp        0      0 0.0.0.0:8432            0.0.0.0:*               LISTEN      40224/pgbackrest\n</code></pre> </li> <li> <p>If you are using Patroni, change its configuration to use <code>pgBackRest</code> for archiving and restoring WAL files. Run this command only on one node, for example, on <code>node1</code>: </p> <pre><code>$ patronictl -c /etc/patroni/patroni.yml edit-config\n</code></pre> Debian/UbuntuRHEL/derivatives /etc/patroni/patroni.yml<pre><code>postgresql:\n  (...)\n  parameters:\n    (...)\n    archive_command: pgbackrest --stanza=cluster_1 archive-push /var/lib/postgresql/16/main/pg_wal/%f\n    (...)\n  recovery_conf:\n    (...)\n    restore_command: pgbackrest --config=/etc/pgbackrest.conf --stanza=cluster_1 archive-get %f %p\n    (...)\n</code></pre> /etc/patroni/patroni.yml<pre><code>postgresql:\n  (...)\n  parameters:\n    archive_command: pgbackrest --stanza=cluster_1 archive-push /var/lib/pgsql/16/data/pg_wal/%f\n    (...)\n  recovery_conf:\n    restore_command: pgbackrest --config=/etc/pgbackrest.conf --stanza=cluster_1 archive-get %f %p\n    (...)\n</code></pre> <p>Reload the changed configurations:</p> <pre><code>$ patronictl -c /etc/patroni/postgresql.yml reload\n</code></pre> <p> Note: When configuring a PostgreSQL server that is not managed by Patroni to archive/restore WALs from the <code>pgBackRest</code> server, edit the server\u2019s main configuration file directly and adjust the <code>archive_command</code> and <code>restore_command</code> variables as shown above."},{"location":"solutions/pgbackrest.html#create-backups","title":"Create backups","text":"<p>Run the following commands on the backup server:</p> <ol> <li> <p>Create the stanza. A stanza is the configuration for a PostgreSQL database cluster that defines where it is located, how it will be backed up, archiving options, etc. </p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 stanza-create\n</code></pre> </li> <li> <p>Create a full backup</p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 --type=full backup\n</code></pre> </li> <li> <p>Check backup info</p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 info\n</code></pre> </li> <li> <p>Expire (remove) a backup:</p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 expire --set=&lt;BACKUP_ID&gt;\n</code></pre> </li> </ol> <p>Test PostgreSQL cluster</p>"},{"location":"solutions/pgbackrest.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/postgis-deploy.html","title":"Deploy spatial data with PostgreSQL","text":"<p>The following document provides guidelines how to install PostGIS and how to run the basic queries. </p>"},{"location":"solutions/postgis-deploy.html#considerations","title":"Considerations","text":"<ol> <li>We assume that you have the basic knowledge of spatial data, GIS (Geographical Information System) and of shapefiles.</li> <li>For uploading the spatial data and querying the database, we use the same data set as is used in PostGIS tutorial. </li> </ol>"},{"location":"solutions/postgis-deploy.html#install-postgis","title":"Install PostGIS","text":"On Debian and UbuntuOn RHEL and derivatives <ol> <li> <p>Enable Percona repository</p> <p>As other components of Percona Distribution for PostgreSQL, PostGIS is available from Percona repositories. Use the <code>percona-release</code> repository management tool to enable the repository. </p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install PostGIS packages</p> <pre><code>$ sudo apt install percona-postgis\n</code></pre> </li> <li> <p>The command in the previous step installs the set of PostGIS extensions. To check what extensions are available, run the following query from the <code>psql</code> terminal:</p> <pre><code>SELECT name, default_version,installed_version\nFROM pg_available_extensions WHERE name LIKE 'postgis%' or name LIKE address%';\n</code></pre> <p>Note</p> <p>To enable the <code>postgis_sfcgal-3</code> extension on Ubuntu 18.04, you need to manually install the required dependency:</p> <pre><code>$ sudo apt-get install libsfcgal1\n</code></pre> </li> </ol> <ol> <li> <p>Check the Platform specific notes and enable required repositories and modules for the dependencies relevant to your operating system.</p> </li> <li> <p>Enable Percona repository    </p> <p>As other components of Percona Distribution for PostgreSQL, PostGIS is available from Percona repositories. Use the <code>percona-release</code> repository management tool to enable the repository.     </p> <pre><code>$ sudo percona-release setup ppg16\n</code></pre> </li> <li> <p>Install the extension    </p> <pre><code>$ sudo yum install percona-postgis33_16 percona-postgis33_16-client\n</code></pre> </li> </ol> <p>This installs the set of PostGIS extensions. To check what extensions are available, run the following query from the <code>psql</code> terminal:        </p> <pre><code>SELECT name, default_version,installed_version\nFROM pg_available_extensions WHERE name LIKE 'postgis%' or name LIKE 'address%';\n</code></pre>"},{"location":"solutions/postgis-deploy.html#enable-postgis-extension","title":"Enable PostGIS extension","text":"<ol> <li> <p>Create a database and a schema for this database to store your data. A schema is a container that logically segments objects (tables, functions, views, and so on) for better management. Run the following commands from the <code>psql</code> terminal:</p> <pre><code>CREATE database nyc;\n\\c nyc;\nCREATE SCHEMA gis;\n</code></pre> </li> <li> <p>To make PostGIS functions and operations work, you need to enable the <code>postgis</code> extension. Make sure you are connected to the database you created earlier and run the following command:</p> <pre><code>CREATE EXTENSION postgis;\n</code></pre> </li> <li> <p>Check that the extension is enabled:</p> <pre><code>SELECT postgis_full_version();\n</code></pre> <p>The output should be similar to the following:</p> <pre><code>postgis_full_version\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n POSTGIS=\"3.3.3\" [EXTENSION] PGSQL=\"140\" GEOS=\"3.10.2-CAPI-1.16.0\" PROJ=\"8.2.1\" LIBXML=\"2.9.13\" LIBJSON=\"0.15\" LIBPROTOBUF=\"1.3.3\" WAGYU=\"0.5.0 (Internal)\"\n</code></pre> </li> </ol>"},{"location":"solutions/postgis-deploy.html#upload-spatial-data-to-postgresql","title":"Upload spatial data to PostgreSQL","text":"<p>PostGIS provides the <code>shp2pgsql</code> command line utility that converts the binary data from shapefiles into the series of SQL commands and loads them into the database.</p> <ol> <li> <p>For testing purposes, download the sample data set:</p> <pre><code>$ curl -LO https://s3.amazonaws.com/s3.cleverelephant.ca/postgis-workshop-2020.zip\n</code></pre> </li> <li> <p>Unzip the archive and from the folder where the <code>.shp</code> files are located, execute the following command and replace the <code>dbname</code> value with the name of your database:</p> <pre><code>shp2pgsql \\\n  -D \\\n  -I \\\n  -s 26918 \\\n  nyc_streets.shp \\\n  nyc_streets \\\n  | psql -U postgres dbname=nyc\n</code></pre> <p>The command does the following:</p> <ul> <li><code>-D</code> flag instructs the command to generate the dump format</li> <li><code>-I</code> flag instructs to create the spatial index on the table upon the data load</li> <li><code>-s</code> indicates the spatial reference identifier of the data. The data we load is in the Projected coordinate system for North America and has the value 26918.</li> <li><code>nyc_streets.shp</code> is the source shapefile</li> <li><code>nyc_streets</code> is the table name to create in the database</li> <li><code>dbname=nyc</code> is the database name</li> </ul> </li> <li> <p>Check the uploaded data</p> </li> </ol> <pre><code>\\d nyc_streets;\n                                         Table \"public.nyc_streets\"\n Column |              Type               | Collation | Nullable |                 Default\n--------+---------------------------------+-----------+----------+------------------------------------------\n gid    | integer                         |           | not null | nextval('nyc_streets_gid_seq'::regclass)\n id     | double precision                |           |          |\n name   | character varying(200)          |           |          |\n oneway | character varying(10)           |           |          |\n type   | character varying(50)           |           |          |\n geom   | geometry(MultiLineString,26918) |           |          |\nIndexes:\n    \"nyc_streets_pkey\" PRIMARY KEY, btree (gid)\n    \"nyc_streets_geom_idx\" gist (geom)\n</code></pre> <ol> <li>Repeat the command to upload other shapefiles in the data set: <code>nyc_census_blocks</code>, <code>nyc_neighborhoods</code>, <code>nyc_subway_stations</code></li> </ol>"},{"location":"solutions/postgis-deploy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/postgis-testing.html","title":"Query spatial data","text":"<p>After you installed and set up PostGIS, let\u2019s find answers to the following questions by querying the database:</p>"},{"location":"solutions/postgis-testing.html#what-is-the-population-of-the-new-york-city","title":"What is the population of the New York City?","text":"<pre><code>SELECT Sum(popn_total) AS population\n  FROM nyc_census_blocks;\n</code></pre> <p>Output:</p> <pre><code>population\n------------\n    8175032\n(1 row)\n</code></pre>"},{"location":"solutions/postgis-testing.html#what-is-the-area-of-central-park","title":"What is the area of Central Park?","text":"<p>To get the answer we will use the <code>ST_Area</code> function that returns the areas of polygons.</p> <pre><code>SELECT ST_Area(geom) / 1000000\n  FROM nyc_neighborhoods\n  WHERE name = 'Central Park';\n</code></pre> <p>Output:</p> <pre><code>      st_area\n--------------------\n 3.5198365965413293\n(1 row)\n</code></pre> <p>By default, the output is given in square meters. To get the value in square kilometers, divide it by 1 000 000.</p>"},{"location":"solutions/postgis-testing.html#how-long-is-columbus-circle","title":"How long is Columbus Circle?","text":"<pre><code>SELECT ST_Length(geom)\n  FROM nyc_streets\n  WHERE name = 'Columbus Cir';\n</code></pre> <p>Output:</p> <pre><code>     st_length\n-------------------\n 308.3419936909855\n(1 row)\n</code></pre>"},{"location":"solutions/postgis-testing.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/postgis-upgrade.html","title":"Spatial database upgrade","text":"<p>When using PostgreSQL and PostGIS for some time, you may eventually come to the decision to upgrade your spatial database. There can be different reasons for that: to receive improvements and/or bug fixes that come with a minor version of the database/extension, reaching the end of life of the currently used software and others.</p> <p>The spatial database upgrade consists of two steps:</p> <ul> <li>upgrade of PostgreSQL, and </li> <li>upgrade of the PostGIS extension. </li> </ul> <p>Important</p> <p>Before the upgrade, backup your data.</p>"},{"location":"solutions/postgis-upgrade.html#upgrade-postgis","title":"Upgrade PostGIS","text":"<p>Each version of PostGIS is compatible with several versions of PostgreSQL and vise versa. The best practice is to first upgrade the PostGIS extension on the source cluster to match the compatible version on the target cluster and then upgrade PostgreSQL. Please see the PostGIS Support matrix for version compatibility. </p> <p>PostGIS is enabled on the database level. This means that the upgrade is also done on the database level. </p> PostGIS 3 and abovePostGIS 2.5 <p>Connect to the database where it is enabled and run the <code>PostGIS_Extensions_Upgrade()</code> function:</p> <pre><code>SELECT postgis_extensions_upgrade();\n</code></pre> <p>Repeat these steps to upgrade PostGIS on every database where it is enabled.</p> <p>Connect to the database with the enabled extension and run the following commands:</p> <pre><code>ALTER EXTENSION postgis UPDATE;\nSELECT postgis_extensions_upgrade();\n</code></pre> <p>Starting with version 3, vector and raster functionalities have been separated in two individual extensions. Thus, to upgrade those, you need to run the <code>postgis_extensions_upgrade();</code> twice.</p> <pre><code>SELECT postgis_extensions_upgrade();\n</code></pre> <p>TIP: If you don\u2019t need the raster functionality, you can drop the <code>postgis_raster</code> extension after the upgrade.</p> <p>Repeat these steps to upgrade PostGIS on every database where it is enabled.</p>"},{"location":"solutions/postgis-upgrade.html#upgrade-postgresql","title":"Upgrade PostgreSQL","text":"<p>Upgrade PostgreSQL either to the latest minor or to the major version.</p> <p>If you are using long deprecated views and functions and / or need the expertise in upgrading your spatial database, contact Percona Managed Services for an individual upgrade scenario development.</p>"},{"location":"solutions/postgis-upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"solutions/postgis.html","title":"Spatial data manipulation","text":"<p>Version added: 15.3</p> <p>Organizations dealing with spatial data need to store it somewhere and manipulate it. PostGIS is the open source extension for PostgreSQL that allows doing just that. It adds support for storing the spatial data types such as:</p> <ul> <li>Geographical data like points, lines, polygons, GPS coordinates that can be mapped on a sphere.</li> <li>Geometrical data. This is also points, lines and polygons but they apply to a 2D surface.</li> </ul> <p>To operate with spatial data inside SQL queries, PostGIS supports spatial functions like distance, area, union, intersection. It uses the spatial indexes like R-Tree and Quadtree for efficient processing of database operations. Read more about supported spatial functions and indexes in PostGIS documentation. </p> <p>By deploying PostGIS with Percona Distribution for PostgreSQL, you receive the open-source spatial database that you can use in various areas without vendor lock-in. </p>"},{"location":"solutions/postgis.html#when-to-use-postgis","title":"When to use PostGIS","text":"<p>You can use PostGIS in the following cases:</p> <ul> <li>To store and manage spatial data, create and store spatial shapes, calculate areas and distances</li> <li>To build the software that visualizes spatial data on a map, </li> <li>To work with raster data, such as satellite imagery or digital elevation models.</li> <li>To integrate spatial and non-spatial data such as demographic or economic data in a database</li> </ul>"},{"location":"solutions/postgis.html#when-not-to-use-postgis","title":"When not to use PostGIS","text":"<p>Despite its power and flexibility, PostGIS may not suit your needs if:</p> <ul> <li>You need to store only a couple of map locations. Consider using the built-in geometric functions and operations of PostgreSQL</li> <li>You need real-time data analysis. While PostGIS can handle real-time spatial data, it may not be the best option for real-time data analysis on large volumes of data.</li> <li>You need complex 3D analysis or visualization.</li> <li>You need to acquire spatial data. Use other tools for this purpose and import spatial data into PostGIS to manipulate it.</li> </ul>"},{"location":"solutions/postgis.html#next-steps","title":"Next steps:","text":"<p>Deployment</p>"},{"location":"solutions/postgis.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"}]}